<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Jiarui Lu</title>
  <icon>https://www.gravatar.com/avatar/68ce4f3ec3d87765e9ad4be701622026</icon>
  <subtitle>Non-Stop</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://jaredlujr.github.io/"/>
  <updated>2020-04-10T12:07:54.445Z</updated>
  <id>http://jaredlujr.github.io/</id>
  
  <author>
    <name>Jiarui Lu</name>
    <email>jaredlujr@gmail.com</email>
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>TD-based Estimation of Action-Value Function</title>
    <link href="http://jaredlujr.github.io/2020/04/10/td-prediction2/"/>
    <id>http://jaredlujr.github.io/2020/04/10/td-prediction2/</id>
    <published>2020-04-10T07:13:20.000Z</published>
    <updated>2020-04-10T12:07:54.445Z</updated>
    
    <content type="html"><![CDATA[<p>On top of our discussion of Monte-Carlo and TD(0) algorithm, we now turn to consider the intermediate one between them.</p><h3 id="n-step-TD"><a href="#n-step-TD" class="headerlink" title="n-step TD"></a>n-step TD</h3><p>If we let TD target $R_{t+1}+\gamma V(S_{t+1})$ look $n$ steps into the future.</p><p><img src="nstep.png" alt="alt nstep"></p><p>Then the algorithm will transform gradually from $TD(0)$ to $MC$.</p><p>We define the $n$-step return:</p><script type="math/tex; mode=display">G_{t}^{(n)} = R_{t+1} + \gamma R_{t+2} + \dots + \gamma^{n-1} R_{t+n} + \gamma^n V(S_{t+n})</script><p>where $n=1$ is the same as TD(0), and $n=\infty$ is the same as MC, which will reach the end of an episode. The update formula is</p><script type="math/tex; mode=display">V(S_t) := V(S_t) + \alpha(G_t^{(n)} - V(S_t))</script><h3 id="TD-lambda-forward"><a href="#TD-lambda-forward" class="headerlink" title="TD($\lambda$): forward"></a>TD($\lambda$): forward</h3><p>The update of Model-free algorithm is based on the episode, say the observation. How to make full use of these information to update is our focus.</p><p>We may consider the “decay” way by factor $\lambda$ of n-step return $G_{t}^{(n)}$ in the following form as $\lambda$-return $G_{t}^{\lambda}$:</p><p><img src="lambda1.png" alt="alt lambda"></p><script type="math/tex; mode=display">G_t^{\lambda} = (1-\lambda) \sum_{n=1}^\infty \lambda^{n-1} G_t^{(n)}</script><p>and update</p><script type="math/tex; mode=display">V(S_t) := V(S_t) + \alpha(G_t^{\lambda} - V(S_t))$$.where $(1-\lambda) \cdot \lambda^{n-1}$ is the weighted decay:- Normalization: $\sum (1-\lambda) \cdot \lambda^{n-1} = 1$- $\lambda=0$, just same as TD(0)- $\lambda=1$, degenerate to MC (only the last term $G_t^{\infty}$ survive)![alt lambda](lambda2.png)### TD($\lambda$): backwardIf we view the TD($\lambda$) backward, we may find some mechanism of the update.By looking backward on an episode, we can define the **Eligibility trace** as follows:$$E_0(s) = 0</script><script type="math/tex; mode=display">E_t(s) = \gamma \lambda E_{t-1}(s) + 1(S_t=s)</script><p>where the future states are not involved.</p><p>With TD-error as:<br>$\delta_t = R_{t+1} + \gamma V(S_{t+1}) - V(S_t)$</p><p>Now the update formula has the form</p><script type="math/tex; mode=display">V(s) := V(s) + \alpha \delta_t E_t(s)</script><p><img src="bv.png" alt="alt bv"></p><h4 id="What-does-the-E-t-s-mean"><a href="#What-does-the-E-t-s-mean" class="headerlink" title="What does the $E_t(s)$ mean?"></a>What does the $E_t(s)$ mean?</h4><p>The Eligibility trace is like a credit assigned to a given state in episodes, and we would like to assign credit to <strong>most frequent states and most recent states</strong>, which are respectively two terms in the definition.</p><p>If we perform offline updates, say update value function after a batch accumulation, then the forward-view and backward-view is <strong>identical</strong>.</p><p>For example, consider an episode whre $s$ is visited once at time-step $k$, then</p><p>$TD(\lambda)$ eligibility trace discounts time since visit,</p><script type="math/tex; mode=display">E_t(s) = \gamma\lambda E_{t+1}(s) + 1(S_t=s) =\begin{cases}0 & if ~ t< k\\(\gamma\lambda)^{t-k} & if ~  t\ge k\end{cases}</script><p>It means that the $E_t(s)$ depends on the “distance” from the appearance at $k$ to current time-step $t$ and target state $s$. We can see it as a decay-weighted effected of visiting a state.</p><h3 id="TD-lambda-and-TD-1"><a href="#TD-lambda-and-TD-1" class="headerlink" title="TD($\lambda$) and TD($1$)"></a>TD($\lambda$) and TD($1$)</h3><p>Under the offline update, the sum of TD errors telescopes into MC error and TD(1) roughly equivalent to every-visit Monte-Carlo. Since the error is accumulated, so the total update result is exactly the same as MC, say the “shattered” MC.</p><p>In summary, the comparison among these algorithms is made as the following table:</p><p><img src="comp.png" alt="alt comp"></p><hr><p><strong>Reference</strong>: <a href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html" target="_blank" rel="noopener">Teaching slides</a> of Prof. David Silver at UCL</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;On top of our discussion of Monte-Carlo and TD(0) algorithm, we now turn to consider the intermediate one between them.&lt;/p&gt;
&lt;h3 id=&quot;n-ste
      
    
    </summary>
    
    
      <category term="Computer-science" scheme="http://jaredlujr.github.io/categories/computer-science/"/>
    
    
      <category term="Machine-learning" scheme="http://jaredlujr.github.io/tags/machine-learning/"/>
    
      <category term="Reinforcement-learnning" scheme="http://jaredlujr.github.io/tags/reinforcement-learnning/"/>
    
      <category term="Model-free" scheme="http://jaredlujr.github.io/tags/model-free/"/>
    
  </entry>
  
  <entry>
    <title>Coset and quotient set of a subgroup</title>
    <link href="http://jaredlujr.github.io/2020/04/10/coset/"/>
    <id>http://jaredlujr.github.io/2020/04/10/coset/</id>
    <published>2020-04-10T06:01:45.000Z</published>
    <updated>2020-04-10T07:10:37.344Z</updated>
    
    <content type="html"><![CDATA[<p>Given group $G$, an important method to study the property of such group is to make the partition into smaller unit. With the help of a subgroup $H$ of $G$, it may be realized.</p><p>In the following part, such partition induced by subgroup $H$ is equivalent to the equivalence relation induced by $H$, or the quotient set generated by $H$.</p><h3 id="Coset-and-Quotient-set"><a href="#Coset-and-Quotient-set" class="headerlink" title="Coset and Quotient set"></a>Coset and Quotient set</h3><p>We directly give the following definition:</p><p>$\overset{H}{\sim}$ is such an equivalence relation in $G$, which indicates that</p><script type="math/tex; mode=display">a\overset{H}{\sim} b, b\in G \Leftrightarrow ab^{-1}\in H</script><p>As far as we’ve concerned, any equivalence relation gives partition of a set: into <strong>several equivalence classes</strong>. Under $a \overset{H}{\sim} b$, the equivalence class of $a$ by $G$ is exactly $aH$, which is called the <strong>left coset</strong> of subgroup $H$. Distinct left cosets of $H$ finish the exhaust of $G$:</p><script type="math/tex; mode=display">G= \bigcup_{a\in L} aH</script><p>where $L$ is the set of generating elements belonging to different equivalence classes.</p><p>Then we denote the number of different left coset of $H$ as $[G:H]$, the index of $H$.</p><p>In fact, there is another equivalence relation as $(\overset{H}{\sim})’$, which will induce the <strong>right coset</strong> of $H$ in $G$. However, what’s interesting is that $[G:H]$ is the same under any of these two equivalence relations, and we have $L^{-1} = R$, where $R$ is the generating elements for right cosets.</p><p>Thus, the index $[G:H]$ is well-defined since it is now independent from the $\overset{H}{\sim}$.</p><p><strong>(Lagrange)</strong> Let $H\le G$, then</p><script type="math/tex; mode=display">|G|= |H|[G:H]$$.Let $L=\{a_1,a_2,\dots,a_n\}$, then we have obtained the quotient set as a collection of different equivalence classes:$$G/H = \{a_1H,\dots,a_nH\}</script><p>Then we will discuss the normal subgroup, which plays an important role in the quotient set partition.</p><p>If we want the quotient set holds the operation among each element(now they are the sets), we will have $aH=Ha$. In fact, we can prove that</p><p><strong>Theorem</strong> $H\triangleleft G \Leftrightarrow G/H $ is a group with operation in $G$.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Given group $G$, an important method to study the property of such group is to make the partition into smaller unit. With the help of a s
      
    
    </summary>
    
    
      <category term="Math" scheme="http://jaredlujr.github.io/categories/math/"/>
    
    
      <category term="Group-theory" scheme="http://jaredlujr.github.io/tags/group-theory/"/>
    
      <category term="Quotient-set" scheme="http://jaredlujr.github.io/tags/quotient-set/"/>
    
      <category term="Abstract-algebra" scheme="http://jaredlujr.github.io/tags/abstract-algebra/"/>
    
  </entry>
  
  <entry>
    <title>PAC assumption</title>
    <link href="http://jaredlujr.github.io/2020/04/08/pac-assumption/"/>
    <id>http://jaredlujr.github.io/2020/04/08/pac-assumption/</id>
    <published>2020-04-08T15:29:49.000Z</published>
    <updated>2020-04-09T00:28:45.710Z</updated>
    
    <content type="html"><![CDATA[<p>Probability approximately correct(PAC) assumption is a plausible but not enough general assumption which ignores the noises: <strong>the training data was drawn from the same distribution $D$</strong>.</p><p>Consider the setting of linear classification, a very simple case, one approach is to try to minimize the training error, and pick the “best”:</p><script type="math/tex; mode=display">\hat\theta = arg\min_\theta \hat\epsilon(h_\theta)</script><p>We call this process <strong>empirical risk minimization</strong>(ERM), which is regarded as the most “basic” learning algorithm. If abstacting away from the specific parameterization of hypotheses, instead, we consider the hypothesis class $H$, where all the classifiers lie. Foe example, in terms of neural networks, we could let $H$ be the set of all classifers <strong>representable</strong> by some neural network architecture. (which is an incredibly wide range of function domain)</p><p>In the case of finite hypothesis space $H$, we can derive the estimation of generalization error by applying <strong>the union bound</strong> and <strong>Chernoff bound</strong>, and give the result in a form including:</p><ul><li>the number of samples $m$</li><li>the confidence $1- \delta$</li><li>$k$, as the order of hypothesis space $H$</li><li>the discrepancy range of errors $\gamma$</li></ul><p>Focusing on the first term! It provides some insights about how many training examples we need to make an enough guarantee on the correctness of our model, in the following way:</p><script type="math/tex; mode=display">m \ge \frac{1}{2\gamma^2}log\frac{2k}{\delta}</script><p>The training set size $m$ that a certain given method or algorithm requires in order to achieve a certain level of performance is also called the <strong>algorithm’s sample complexity.</strong></p><p>We can also express the generalization error of the best hypothesis we can find in the following relative way:</p><script type="math/tex; mode=display">\epsilon(\hat h) \leq (min_{h\in H}\epsilon (h) + 2\gamma)</script><p>which means that the uniform convergence occurs with probability at least $1-\delta$. Thus, we bound the error in some ways.</p><p>As for the infinite $H$ case, we change the way of analysis and define the <strong>Vapnik-Chervonenkis dimension(VC dimension)</strong> of given hypothesis class $H$, written $VC(H)$. It is the size of the largest set that is <strong>shattered</strong> by $H$.</p><p>We say that $H$ shatters $S$ if $H$, i.e. considering all the $h\in H$, are able to realize any labeling on $S$. The discussion focuses on fixed arrangement of points in fixed amount $d$ but arbitrary labeling. This is to say, in order to prove that $VC(H)$ is at least $d$, we need to show only that there exists at least one specific set of size $d$ that $H$ can shatter.</p><p>For example, the linear hypotheses $h\in \mathbb R^2$ cannot shatter any four points on the plane, and in fact it cannot either shatter the three points in a line, but can work otherwise. Thus, the VC dimension is $3$.</p><p>With $VC(H)=d$ defined, we are equipped with a proper tool to describe the error bound, at least the order of it. Generally speaking, how the $\epsilon(\hat h)$ will change along with the number of examples $m$. It can be proved that such proportion stays linear.</p><p><strong>Theorem</strong> Given $H$, let $d=VC(H)$. Then with probability at least $1-\delta$, we have:</p><script type="math/tex; mode=display">\epsilon(\hat h) \leq \epsilon(h^\ast) + O\left( \sqrt{\frac{d}{m}log \frac{m}{d} + \frac{1}{m}log \frac{1}{\delta}}\right)</script><hr><p><strong>Reference</strong>:</p><p><a href="http://cs229.stanford.edu/notes/cs229-notes4.pdf" target="_blank" rel="noopener">Stanford CS229-note4</a> by Andrew Ng<br>Statistical Learning methods, by Li Hang (2012)</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Probability approximately correct(PAC) assumption is a plausible but not enough general assumption which ignores the noises: &lt;strong&gt;the 
      
    
    </summary>
    
    
      <category term="Computer-science" scheme="http://jaredlujr.github.io/categories/computer-science/"/>
    
    
      <category term="Machine-learning" scheme="http://jaredlujr.github.io/tags/machine-learning/"/>
    
      <category term="Learning-theory" scheme="http://jaredlujr.github.io/tags/learning-theory/"/>
    
      <category term="Error-estimation" scheme="http://jaredlujr.github.io/tags/error-estimation/"/>
    
  </entry>
  
  <entry>
    <title>Learning theory in Machine learning</title>
    <link href="http://jaredlujr.github.io/2020/04/08/learning-theory/"/>
    <id>http://jaredlujr.github.io/2020/04/08/learning-theory/</id>
    <published>2020-04-08T14:23:19.000Z</published>
    <updated>2020-04-09T00:28:43.941Z</updated>
    
    <content type="html"><![CDATA[<p>Learning theory is necessary when it comes to properly evaluate a specific learning algorithm. In Numerical Analysis, many evaluation methods and standards are established to help judge “how good” the algorithm or model is, such as errors, convergence speed, convergence domain and so on. Likewise, we eagerly want to know about the machine learning methods.</p><p>In terms of the goal in machine learning, most of them are classification. More generally speaking, we would like to learning something derived from a given dataset, say some amount of data points $T = \{(x^{(i)},y^{(i)})\}$. The Machine Learning is also called Statistical Learning, since most of the the tasks are partially or totally based on the data.</p><p>However, the data is sampled as the observation from human, which may contain some noises, or even worse, not strictly follow specific distribution. The topic in this article is to make an exposition: under some assumptions, how to evaluate a given model, even if we cannot accurately give what the errors are, but nevertheless restrict them within some boundaries.</p><h3 id="Trade-off-bias-or-variance"><a href="#Trade-off-bias-or-variance" class="headerlink" title="Trade-off: bias or variance"></a>Trade-off: bias or variance</h3><p>Like what happens in the classic interpolation and curve fitting scenario, there exists a trade-off to use simple or complex function(hypothesis) to generate the best “resonance” to the given data.</p><p>In machine learning, we define the generalization error of a hypothesis is its expected error on examples not necessarily in the training set.</p><p>We will call the errors resulted from over-simple hypothesis as <strong>bias</strong>; on the contrary, that of data over-fitting is called <strong>variance</strong>.</p><p>This is straightforward! Because the observed data source does not probably obey the probability distribution as far as we’ve concerned, so the emergence of error makes sense and inevitable; however, we can absolutely make the best fitting with no error at all by memorizing the data, say using higher-polynomial with tons of parameters. It is exactly what has happened in the curve fitting case: the fitting line loses any regularity but be extremely rigid.</p><h3 id="Empirical-error-and-real-error"><a href="#Empirical-error-and-real-error" class="headerlink" title="Empirical error and real error"></a>Empirical error and real error</h3><p>Actually, we have to agree on one thing that we can never know the “real” distribution of a given dataset (otherwise, there is no need to perform machine learning experiment!), so the only perception is how well the model works on such dataset.</p><h4 id="Empirical-risk-error"><a href="#Empirical-risk-error" class="headerlink" title="Empirical risk (error)"></a>Empirical risk (error)</h4><p>Empirical risk has a natural definition by simply counting the average misclassified samples:</p><script type="math/tex; mode=display">\hat\epsilon(h) = \frac{1}{m} \sum_{i=1}^m 1\{h(x^{(i)}) \neq y^{(i)}\}</script><p>However, what we really care is the following one: <strong>generalization error</strong>, which indicates the real performance on arbitrary data from real distribution.</p><script type="math/tex; mode=display">\epsilon(h) = P_{(x,y)\sim D} (h(x)\neq y)</script><p>If we draw a new examle $(x,y)$ from the distribution $D$, $h$ will misclassify it.</p><p>However, in order to give a clear insight about the generalization error, we need to talk about the hypotheses under the <strong>PAC</strong> assumptions.</p><hr><p><strong>Reference</strong>:</p><p><a href="http://cs229.stanford.edu/notes/cs229-notes4.pdf" target="_blank" rel="noopener">Stanford CS229-note4</a> by Andrew Ng<br>Statistical Learning methods, by Li Hang (2012)</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Learning theory is necessary when it comes to properly evaluate a specific learning algorithm. In Numerical Analysis, many evaluation met
      
    
    </summary>
    
    
      <category term="Computer-science" scheme="http://jaredlujr.github.io/categories/computer-science/"/>
    
    
      <category term="Machine-learning" scheme="http://jaredlujr.github.io/tags/machine-learning/"/>
    
      <category term="Learning-theory" scheme="http://jaredlujr.github.io/tags/learning-theory/"/>
    
      <category term="Error-estimation" scheme="http://jaredlujr.github.io/tags/error-estimation/"/>
    
  </entry>
  
  <entry>
    <title>Recurrence Relation</title>
    <link href="http://jaredlujr.github.io/2020/04/07/recurrence-relation/"/>
    <id>http://jaredlujr.github.io/2020/04/07/recurrence-relation/</id>
    <published>2020-04-07T11:58:33.000Z</published>
    <updated>2020-04-07T14:35:13.164Z</updated>
    
    <content type="html"><![CDATA[<p>There are basically three ways to determine a sequence $\{a_n,n\ge 0\}$, explicitly or implicitly.</p><ul><li>Explicit expression as: $a_n = A(n)$</li><li>Generation function of $a_n$ as $A(x) = \sum_{n=0}^\infty a_n x^n$</li><li>Build the <strong>Recurrence Relation</strong>, which contains<ul><li>relation: $a_n = F(a_{n-1},a_{n-2},\dots, a_{n-r};n)$</li><li>initial condition: $a_1;a_2;\dots$</li></ul></li></ul><h3 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h3><p>For example, the <strong>Hanoi</strong> is a typical problem of it, which has the following recurrence relation:</p><script type="math/tex; mode=display">a_n=2a_{n-1} +1, n \ge 2</script><script type="math/tex; mode=display">a_1 = 1</script><p>Iteratively solve the relation, we have explicit form as follow:</p><script type="math/tex; mode=display">a_n = 2a_{n-1} + 1 = 2(2a_{n-2}+1) +1 =\dots = 2^n -1</script><p><strong>Fibonacci</strong> and <strong>Catalan</strong> Sequence are also famous examples for recurrence. Especially we can solve the Fibonacci thoroughly:</p><h4 id="Fibonacci"><a href="#Fibonacci" class="headerlink" title="Fibonacci"></a>Fibonacci</h4><script type="math/tex; mode=display">f_n = f_{n-1} + f_{n-2}. f_0=f_1= 1</script><p>We can solve the general formula of $f_n$ by generation function.</p><p>Let $F(x)= \sum_{n\ge 0} f_n x^n$, then</p><script type="math/tex; mode=display">F(x) = f_0+f_1 x + \sum_{n\ge 2} f_nx^n = 1+ x+x(F(x)-1) + x^2F(x) =1+xF(x) + x^2F(x)</script><p>Thus,</p><script type="math/tex; mode=display">F(x) = \frac{1}{1-x-x^2} = \frac{1}{\sqrt5} (\frac{\alpha}{1-\alpha x} - \frac{\beta}{1-\beta x}) = \frac{1}{\sqrt5}(\alpha^{n+1}- \beta^{n+1}) x^n</script><p>where $\alpha={1\over2}(1+\sqrt5), \beta ={1\over 2}(1-\sqrt5)$, the eigenvalue of the recurrence relation.</p><p>The practical instance for Fibonacci is the number of $n-$sequence of $\{0,1\}$ with no adjacent $1$, like $1010001\dots$</p><h4 id="Catalan"><a href="#Catalan" class="headerlink" title="Catalan"></a>Catalan</h4><p>Catalan describes the possible associative combination of $n$-element string $x_1x_2\dots x_n$, where the associative law is not necessary to satisfy between $xy$.</p><p>The recurrence relation is graceful:</p><script type="math/tex; mode=display">c_n = c_0 c_{n-1} + c_1 c_{n-2} + \dots+ c_{n-1}c_0 = \sum_{j=0}^{n-1} c_j c_{n-1-j}; ~c_0 = c_1=1</script><h3 id="General-recurrence-relation"><a href="#General-recurrence-relation" class="headerlink" title="General recurrence relation"></a>General recurrence relation</h3><p>Here we briefly introduce several common recurrence relations, where each of them has corresponding general solution.</p><h4 id="1-First-order-Linear-recurrence-sequence-LRS"><a href="#1-First-order-Linear-recurrence-sequence-LRS" class="headerlink" title="1. First order Linear recurrence sequence(LRS)"></a>1. First order Linear recurrence sequence(LRS)</h4><script type="math/tex; mode=display">u_n=a(n) u_{n-1} + b(n) ,a(n)\neq 0, n\ge 0</script><p>By dividing $a(n)$, we instead study the recurrence relation of new sequence $\tilde{u_{n}}$ with constant coefficiencts.</p><h4 id="2-r-order-linear-recurrence-relation-with-constant-coefficients"><a href="#2-r-order-linear-recurrence-relation-with-constant-coefficients" class="headerlink" title="2. $r$-order linear recurrence relation with constant coefficients"></a>2. $r$-order linear recurrence relation with constant coefficients</h4><p>Just like what we do in the differential equation: homogeneous and non-homogeneous case to discuss.</p><script type="math/tex; mode=display">u_n = \sum_{j=1}^r c_j u_{n-j} + g(n)</script><p>where $g(n)$ is the non-homogeneous term, and $c_j$ is irrelevant to $n$.</p><p>For example, the Fibonacci $f_n = f_{n-1} + f_{n-2} $ is $2$-order homogeneous LRS.</p><p>For $r$-order homogeneous LRS, we have the general solution which is determined by solving eigenpolynomial and eigenvalue.</p><script type="math/tex; mode=display">u_n = \sum_{j=1}^r c_j u_{n-j}</script><script type="math/tex; mode=display">c(x ) = x^r - \sum_{j=1}^r c_j x^{r-j} = (x-\alpha_1)^{e_1}\dots (x-\alpha_s)^{e_s}</script><p>where $s$ is the number of distinct solution and $e_s$ is the corresponding multiplicity of $\alpha_s$. Also, $e_1+\dots+e_s=r$.</p><p>Then</p><script type="math/tex; mode=display">u_n = p_1(n) \alpha_1^n + \dots + p_s(n) \alpha_s^n, ~deg(p_i)<e_i</script><p>And the sumup number of coefficiencts in $p_i(n)$ is $r$ can be uniquely determined by initial value $u_0,u_1,\dots,u_{r-1}$.</p><p>For non-homogeneous case, we need to find a special solution that satisfies:</p><script type="math/tex; mode=display">u_n=u_n' + \sum_{i=1}^s p_i(n)\alpha_i^n</script><h3 id="Convolutional-recurrence-relation"><a href="#Convolutional-recurrence-relation" class="headerlink" title="Convolutional recurrence relation"></a>Convolutional recurrence relation</h3><p>We define that the sum $\sum_{j=0}^n u_j v_{n-j}$ is the convolution of vector $(u_0,\dots,u_n)^T,(v_0,\dots,v_n)^T$. And such recurrence relation is called Convolutional Form.</p><p>As mentioned above, the Catalan Sequence has the following form:</p><script type="math/tex; mode=display">c_n =  \sum_{j=0}^{n-1} c_j c_{n-1-j}; ~c_0 =c_1= 1</script><p>We can solve it by generating function and eigenfunction tricks, finally we have:</p><script type="math/tex; mode=display">c_n = \frac{1}{n+1} \binom{2n}{n}</script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;There are basically three ways to determine a sequence $\{a_n,n\ge 0\}$, explicitly or implicitly.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Explicit expression as: $
      
    
    </summary>
    
    
      <category term="Math" scheme="http://jaredlujr.github.io/categories/math/"/>
    
    
      <category term="Combinatorics" scheme="http://jaredlujr.github.io/tags/combinatorics/"/>
    
      <category term="Sequence" scheme="http://jaredlujr.github.io/tags/sequence/"/>
    
      <category term="Recurrence" scheme="http://jaredlujr.github.io/tags/recurrence/"/>
    
  </entry>
  
  <entry>
    <title>Generating function of integer partition</title>
    <link href="http://jaredlujr.github.io/2020/04/07/integer-partition-gf/"/>
    <id>http://jaredlujr.github.io/2020/04/07/integer-partition-gf/</id>
    <published>2020-04-07T10:56:25.000Z</published>
    <updated>2020-04-07T12:19:16.641Z</updated>
    
    <content type="html"><![CDATA[<p>Partition of a positive number, is also an important counting objective in Combinatorics. As a combination form of counting, it means that the number of possible partitions of $n$. For example,</p><script type="math/tex; mode=display">4 = 3+1=2+2=2+1+1=1+1+1+1</script><p>Totally $4$ ways to take the partition, we denoted that $p(4) = 4$, where $p(n)$ is general form of integer partition.</p><h3 id="Common-restricted-integer-partitions"><a href="#Common-restricted-integer-partitions" class="headerlink" title="Common restricted integer partitions"></a>Common restricted integer partitions</h3><p>There are several restricted integer partition:</p><ul><li>$p(n,r)$: counting those with exactly $r$ parts; notice that $p(n) = \sum_k p(n,k)$</li><li>$n\in \mathbb N, H\subset \mathbb N \to p_H(n)$, where each part belong to $H$</li><li>In particular, $r,n\in \mathbb N \to p_{[r]}(n)$, where each part belong to $[r]$, say each part is less than or equal to $r$</li><li>$p_{\neq}(n)$ denotes the integer partition with distinct parts</li><li>$p_{odd}(n),p_{even}(n)…$</li></ul><h3 id="Ferrers-diagram"><a href="#Ferrers-diagram" class="headerlink" title="Ferrers diagram"></a>Ferrers diagram</h3><p>In fact, there is a convenient way to represent any partition straightforward, by Ferrers diagram:</p><div align=center><img src="ferrers.png" width="40%" height="40%"></div><p>which is a bijective image with $6+4+3+1$.</p><h3 id="Generating-Function"><a href="#Generating-Function" class="headerlink" title="Generating Function"></a>Generating Function</h3><p>Integer partition can also be analysed by generating Function, and any restricted partition can be correspondingly transformed to the variant function.</p><p>Generally, we write the generating function as follows:</p><script type="math/tex; mode=display">P(x) = \sum_{n=0}^\infty p(n)x^n = \prod_{j=1}^\infty (1-x^j)^{-1}</script><p><strong>Why? Let’s see</strong></p><p>Expand the $P(x)$:</p><script type="math/tex; mode=display">(1+x+x^2+\dots)(1+x^2+x^4+\dots)\dots = \prod_{j=1}^\infty (1-x^j)^{-1}</script><p>The coefficient of $x^n$ is contributed from each factor. Let $x_j$ be the number of parts containing $j$ elements, say $”1”$. Then we transform the known problem into the following Diophantus equation:</p><script type="math/tex; mode=display">x_1 + 2x_2 +\dots  = n</script><p>Then the result is clear.</p><p>Furthermore, we can add extra restriction by adjust the product form, take $p_H(n)$ for example:</p><script type="math/tex; mode=display">P_H(x) = \sum_{n=0}^\infty p_H(n) x^n = \prod_{j\in H} (1-x^j)^{-1}</script><h3 id="Inverse-generating-Function"><a href="#Inverse-generating-Function" class="headerlink" title="Inverse generating Function"></a>Inverse generating Function</h3><p>We define the inverse of $P(x)$ as $Q(x) =\sum_{n=0}^\infty q(n) x^n \equiv \prod_{j\in H} (1-x^j)$, such that $P(x)Q(x)=1$.</p><p>The $q(n)$ satisfies the following equation:</p><script type="math/tex; mode=display">q(n) = q_0(n) - q_1(n)</script><p>where $q_0(n)$ is the number of partitions of $n$ with distinct even parts while $q_1(n)$ is distinct odd one. Moreover, we have more direct expression of $q(n)$:</p><script type="math/tex; mode=display">q(n)=\begin{cases}(-1)^k, & \text{when } n=\frac{3k^2\pm k}{2} \\0 & \text{otherwise}\end{cases}</script><p>which can be proved by Ferrers diagram through discussion covering each cases.</p><h3 id="Euler’s-Identity"><a href="#Euler’s-Identity" class="headerlink" title="Euler’s Identity"></a>Euler’s Identity</h3><p>On top of the explicit expression of $q(n)$ above, we can immediately deduce the following formula:</p><h4 id="Theory-1"><a href="#Theory-1" class="headerlink" title="Theory-1"></a>Theory-1</h4><script type="math/tex; mode=display">\prod_{j=1}^\infty (1-x^j) = \sum_{n=0}^\infty q(n)x^n = 1+ \sum_{k=1}^\infty (-1)^k \left(x^{\frac{3k^2-k}{2}} + x^{\frac{3k^2+k}{2}}\right)</script><script type="math/tex; mode=display">= 1-x-x^2+x^5+x^7-x^{12}-x^{15}+ \dots</script><h4 id="Theory-2"><a href="#Theory-2" class="headerlink" title="Theory-2"></a>Theory-2</h4><p>Because the inverse property of $Q(x)$ by $P(x)Q(x) =1$, with plugged in, we have the further conclusion:</p><script type="math/tex; mode=display">p(n) = p(n-1) + p(n-1) - \dots  = \sum_{k=1}^\infty (-1)^{k-1} \left(p(n-\frac{3k^2-k}{2}) + p(n-\frac{3k^2+k}{2}) \right)</script><p>And we let $p(m)\equiv 0, \text{ when } m&lt;0$.</p><hr><p><strong>References:</strong> Wikipedia: <a href="https://en.wikipedia.org/wiki/Partition_(number_theory" target="_blank" rel="noopener">Partition</a>)</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Partition of a positive number, is also an important counting objective in Combinatorics. As a combination form of counting, it means tha
      
    
    </summary>
    
    
      <category term="Math" scheme="http://jaredlujr.github.io/categories/math/"/>
    
    
      <category term="Combinatorics" scheme="http://jaredlujr.github.io/tags/combinatorics/"/>
    
      <category term="Generating function" scheme="http://jaredlujr.github.io/tags/generating-function/"/>
    
      <category term="Partition" scheme="http://jaredlujr.github.io/tags/partition/"/>
    
  </entry>
  
  <entry>
    <title>Parity of permutation</title>
    <link href="http://jaredlujr.github.io/2020/04/06/parity-of-p/"/>
    <id>http://jaredlujr.github.io/2020/04/06/parity-of-p/</id>
    <published>2020-04-06T01:39:14.000Z</published>
    <updated>2020-04-06T02:10:54.683Z</updated>
    
    <content type="html"><![CDATA[<p>The subgroups of the symmetric group $S(\Omega)$ over $\Omega$ are called transformation group on $\Omega$. In particular, if $\Omega$ as finite set with $n$ elements, then the subgroups are called permutation groups. $\forall \sigma \in S_n$ forms an one-to-one on $\Omega$, which is also a <strong>permutation</strong>.</p><script type="math/tex; mode=display">\left(\begin{array}{ccc}1 & 2 & 3 & 4 & 5\\\sigma(1) & \sigma(2) & \sigma(3) & \sigma(4) & \sigma(5)\end{array}\right)</script><p>According to Carley, $\forall $ group $G$ is isomorphic with some transformation group; $\forall $ finite group $G$ is isomorphic with some permutation group. This implies the permutations exhibit great importance in the finite algebra structure.</p><h3 id="Property-of-permutation"><a href="#Property-of-permutation" class="headerlink" title="Property of permutation"></a>Property of permutation</h3><p>In fact, we have the following propsition or property of permutation.</p><ul><li>$\forall \sigma \in S_n$ has disjoint cyclic decomposition, which $\exist ~1$<ul><li>cycle can be seen as a special permutation only acting on some elements</li></ul></li><li>If two cycles share no common elements, then they can exchange (exchangable)</li><li>$\forall$ $k$-ary cycle can be further decomposed into product of $k-1$ transportation<ul><li>$2$-ary cycle is called transportation<script type="math/tex; mode=display">(a_1\dots,a_k) = (a_1a_k)(a_1a_{k-1})\dots(a_1a_2)</script></li></ul></li><li>Any transportation $(i,j)$ can be written as the product of<br>$2|j-i|-1$ adjacent transportations. For example:</li></ul><script type="math/tex; mode=display">(2~5) = (2~3)(3~4)(4~5)(4~3)(3~2)</script><h3 id="Parity-of-permutation"><a href="#Parity-of-permutation" class="headerlink" title="Parity of permutation"></a>Parity of permutation</h3><p>Actually, we would like to give a definition of the number of transportations after the decomposition of a permutation $\sigma$, due to the good properties of such discussion.</p><p>Like the collection of all even permutations constructs a subgroup of $S_n$, denoted as $A_n$ and called $n$-ary <strong>alternating group;</strong> and all the odd permutations form the coset of $A_n$. Also, $A_n$ is the normal subgroup of $S_n$ with $index~=2$.</p><p>And let $\sigma_1, \sigma_2$ be even permutation, $\tau_1, \tau_2$ be odd permutation, we have :</p><ul><li>$\sigma \tau$ is odd</li><li>$\sigma_1 \sigma_2$, $\tau_1 \tau_2$ is even</li><li>The parity of permutation is equivalent to the parity of the number of decomposed transportations</li></ul><p>However, we have to prove that such parity is “well-defined”, since the transportation-decomposition is definitely not unique. But we will show that the number of factors in such decomposition holds parity.</p><h3 id="Proof-that-the-parity-of-a-permutation-is-well-defined"><a href="#Proof-that-the-parity-of-a-permutation-is-well-defined" class="headerlink" title="Proof that the parity of a permutation is well-defined"></a>Proof that the parity of a permutation is well-defined</h3><p><em>(using polynomial)</em></p><p>First we define the parity of a permutation is a sign function as:</p><script type="math/tex; mode=display">sgn: S_n \to \{-1,1\}</script><p>where alternating group $A_n$, say the subgroup of all even permutation is the preimage of $+1$.</p><p>Then for $\forall \sigma \in S_n$, we define</p><script type="math/tex; mode=display">sgn(\sigma) = \frac{P(x_{\sigma(1)}, \dots, x_{\sigma(n)})}{P(x_1,\dots,x_n)}</script><p>where polynomial $P(x_1,\dots,x_n) = \prod_{i&lt;j}(x_i-x_j)$; for example, in the case $n=3$, we have $P(x_1,x_2,x_3) = (x_1-x_2)(x_1-x_3)(x_2-x_3)$.</p><p>Apparently there are both identical $\binom{n}{2}$ factors in the denominator and numerator, with <strong>sign</strong> as the only difference. Then we can show that such difference is exactly the sign $sgn(\sigma)$ we have already defined:</p><ul><li>The permutation $\sigma$ is equivalent to its transportation decomposition, which is not unique though.</li><li>Each transportation, as $2$-ary cycle, contribute $-1$ to the whole product, since $(x_i-x_j) = (-1)(x_j-x_i)$</li><li>We see that if $\sigma,r$ are two permutation, then:</li></ul><script type="math/tex; mode=display">sgn(\sigma ~ \tau) = \frac{P(x_{\sigma(\tau(1))}, \dots, x_{\sigma(\tau(n))})}{P(x_1,\dots,x_n)} = \frac{P(x_{\tau(1)}, \dots, x_{\tau(n)})}{P(x_1,\dots,x_n)} \cdot \frac{P(x_{\sigma(\tau(1))}, \dots, x_{\sigma(\tau(n))})}{P(x_{\tau(1)},\dots,x_{\tau(n)})} = sgn(\sigma) sgn(\tau)</script><ul><li>Thus, $sgn(\sigma)$ is the same mapping as we defined earlier. And the parity of $\sigma$ is definite because they only have one value and are indeed well-defined.</li></ul><hr><p><strong>Reference</strong><br>Wikipedia: <a href="https://en.wikipedia.org/wiki/Parity_of_a_permutation" target="_blank" rel="noopener">Parity of a permutation</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;The subgroups of the symmetric group $S(\Omega)$ over $\Omega$ are called transformation group on $\Omega$. In particular, if $\Omega$ as
      
    
    </summary>
    
    
      <category term="Math" scheme="http://jaredlujr.github.io/categories/math/"/>
    
    
      <category term="Group-theory" scheme="http://jaredlujr.github.io/tags/group-theory/"/>
    
      <category term="Abstract-algebra" scheme="http://jaredlujr.github.io/tags/abstract-algebra/"/>
    
      <category term="Permutation" scheme="http://jaredlujr.github.io/tags/permutation/"/>
    
  </entry>
  
  <entry>
    <title>State Pattern by OOP in Python3</title>
    <link href="http://jaredlujr.github.io/2020/04/04/state-pattern/"/>
    <id>http://jaredlujr.github.io/2020/04/04/state-pattern/</id>
    <published>2020-04-04T02:27:13.000Z</published>
    <updated>2020-04-04T02:47:17.643Z</updated>
    
    <content type="html"><![CDATA[<p>State pattern, or state machine is one of the patterns in <strong>Design pattern</strong>. It is proposed to aviod redundancy of code, if tons of if-else statements are needed, which makes it extremely hard to maintain and read the code.</p><p>Here is the solution, by defining the conditions as abstract states, by means of python-class implemented in Python3.</p><h2 id="State-Pattern"><a href="#State-Pattern" class="headerlink" title="State Pattern"></a>State Pattern</h2><p>Goal: To handle different states. Create a state machine which is able to perform corresponding operations given state. If-else free.</p><p>In this designment, each state instance(object) has only static methods without storing any attribute data.</p><h3 id="Primal-class-file-I-O"><a href="#Primal-class-file-I-O" class="headerlink" title="Primal class: file I/O"></a>Primal class: file I/O</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Connection</span>:</span></span><br><span class="line">    <span class="comment"># if-else piled up, with states as "open" or "close"</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.state = <span class="string">'CLOSED'</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">read</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> self.state != <span class="string">'OPEN'</span>:</span><br><span class="line">            <span class="keyword">raise</span> RuntimeError(<span class="string">'Not open'</span>)</span><br><span class="line">        print(<span class="string">'reading'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">write</span><span class="params">(self, data)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> self.state != <span class="string">'OPEN'</span>:</span><br><span class="line">            <span class="keyword">raise</span> RuntimeError(<span class="string">'Not open'</span>)</span><br><span class="line">        print(<span class="string">'writing'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> self.state == <span class="string">'OPEN'</span>:</span><br><span class="line">            <span class="keyword">raise</span> RuntimeError(<span class="string">'Already open'</span>)</span><br><span class="line">        self.state = <span class="string">'OPEN'</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> self.state == <span class="string">'CLOSED'</span>:</span><br><span class="line">            <span class="keyword">raise</span> RuntimeError(<span class="string">'Already closed'</span>)</span><br><span class="line">        self.state = <span class="string">'CLOSED'</span></span><br></pre></td></tr></table></figure><h3 id="Better-solution"><a href="#Better-solution" class="headerlink" title="Better solution"></a>Better solution</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Connection1</span>:</span></span><br><span class="line">    <span class="comment"># define a class for each state</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.new_state(ClosedConnectionState)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">new_state</span><span class="params">(self, newstate)</span>:</span></span><br><span class="line">        self._state = newstate</span><br><span class="line">        <span class="comment"># Delegate to the state class</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">read</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self._state.read(self)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">write</span><span class="params">(self, data)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self._state.write(self, data)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self._state.open(self)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self._state.close(self)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Connection state base class</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConnectionState</span>:</span></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">read</span><span class="params">(conn)</span>:</span></span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError()</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">write</span><span class="params">(conn, data)</span>:</span></span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError()</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open</span><span class="params">(conn)</span>:</span></span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError()</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close</span><span class="params">(conn)</span>:</span></span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Implementation of different states</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ClosedConnectionState</span><span class="params">(ConnectionState)</span>:</span></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">read</span><span class="params">(conn)</span>:</span></span><br><span class="line">        <span class="keyword">raise</span> RuntimeError(<span class="string">'Not open'</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">write</span><span class="params">(conn, data)</span>:</span></span><br><span class="line">        <span class="keyword">raise</span> RuntimeError(<span class="string">'Not open'</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open</span><span class="params">(conn)</span>:</span></span><br><span class="line">        conn.new_state(OpenConnectionState)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close</span><span class="params">(conn)</span>:</span></span><br><span class="line">        <span class="keyword">raise</span> RuntimeError(<span class="string">'Already closed'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">OpenConnectionState</span><span class="params">(ConnectionState)</span>:</span></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">read</span><span class="params">(conn)</span>:</span></span><br><span class="line">        print(<span class="string">'reading'</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">write</span><span class="params">(conn, data)</span>:</span></span><br><span class="line">        print(<span class="string">'writing'</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open</span><span class="params">(conn)</span>:</span></span><br><span class="line">        <span class="keyword">raise</span> RuntimeError(<span class="string">'Already open'</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close</span><span class="params">(conn)</span>:</span></span><br><span class="line">        conn.new_state(ClosedConnectionState)</span><br></pre></td></tr></table></figure><p>But what is “staticmethod”?</p><p>Here is the document in Python3.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">class staticmethod(object)</span><br><span class="line"> |  staticmethod(function) -&gt; method</span><br><span class="line"> |</span><br><span class="line"> |  Convert a function to be a static method.</span><br><span class="line"> |</span><br><span class="line"> |  A static method does not receive an implicit first argument.</span><br><span class="line"> |  To declare a static method, use this idiom:</span><br><span class="line"> |</span><br><span class="line"> |       class C:</span><br><span class="line"> |           @staticmethod</span><br><span class="line"> |           def f(arg1, arg2, ...):</span><br><span class="line"> |               ...</span><br><span class="line"> |</span><br><span class="line"> |  It can be called either on the class (e.g. C.f()) or on an instance</span><br><span class="line"> |  (e.g. C().f()).  The instance is ignored except for its class.</span><br><span class="line"> |</span><br><span class="line"> |  Static methods in Python are similar to those found in Java or C++.</span><br><span class="line"> |  For a more advanced concept, see the classmethod builtin.</span><br></pre></td></tr></table></figure><h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>c = Connection()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c._state</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">__main__</span>.<span class="title">ClosedConnectionState</span>'&gt;</span></span><br><span class="line"><span class="class">&gt;&gt;&gt; <span class="title">c</span>.<span class="title">read</span><span class="params">()</span></span></span><br><span class="line"><span class="class"><span class="title">Traceback</span> <span class="params">(most recent call last)</span>:</span></span><br><span class="line">    File <span class="string">"&lt;stdin&gt;"</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">    File <span class="string">"example.py"</span>, line <span class="number">10</span>, <span class="keyword">in</span> read</span><br><span class="line">        <span class="keyword">return</span> self._state.read(self)</span><br><span class="line">    File <span class="string">"example.py"</span>, line <span class="number">43</span>, <span class="keyword">in</span> read</span><br><span class="line">        <span class="keyword">raise</span> RuntimeError(<span class="string">'Not open'</span>)</span><br><span class="line">RuntimeError: Not open</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c.open()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c._state</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">__main__</span>.<span class="title">OpenConnectionState</span>'&gt;</span></span><br><span class="line"><span class="class">&gt;&gt;&gt; <span class="title">c</span>.<span class="title">read</span><span class="params">()</span></span></span><br><span class="line"><span class="class"><span class="title">reading</span></span></span><br><span class="line"><span class="class">&gt;&gt;&gt; <span class="title">c</span>.<span class="title">write</span><span class="params">(<span class="string">'hello'</span>)</span></span></span><br><span class="line"><span class="class"><span class="title">writing</span></span></span><br><span class="line"><span class="class">&gt;&gt;&gt; <span class="title">c</span>.<span class="title">close</span><span class="params">()</span></span></span><br><span class="line"><span class="class">&gt;&gt;&gt; <span class="title">c</span>.<span class="title">_state</span></span></span><br><span class="line"><span class="class">&lt;<span class="title">class</span> '<span class="title">__main__</span>.<span class="title">ClosedConnectionState</span>'&gt;</span></span><br></pre></td></tr></table></figure><hr><p><strong>Reference</strong>: <a href="https://www.oreilly.com/catalog/errata.csp?isbn=9781449340377" target="_blank" rel="noopener">_David Beazley, Brian K. Jones, Python Cookbook, 3rd Edition_</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;State pattern, or state machine is one of the patterns in &lt;strong&gt;Design pattern&lt;/strong&gt;. It is proposed to aviod redundancy of code, if
      
    
    </summary>
    
    
      <category term="Computer-science" scheme="http://jaredlujr.github.io/categories/computer-science/"/>
    
    
      <category term="Python3" scheme="http://jaredlujr.github.io/tags/python3/"/>
    
      <category term="OOP" scheme="http://jaredlujr.github.io/tags/oop/"/>
    
      <category term="Design-pattern" scheme="http://jaredlujr.github.io/tags/design-pattern/"/>
    
  </entry>
  
  <entry>
    <title>Monte-Carlo and Temporal-Difference Learning</title>
    <link href="http://jaredlujr.github.io/2020/04/03/mctd-evaluation/"/>
    <id>http://jaredlujr.github.io/2020/04/03/mctd-evaluation/</id>
    <published>2020-04-03T11:45:10.000Z</published>
    <updated>2020-04-10T07:16:52.459Z</updated>
    
    <content type="html"><![CDATA[<p>Model-free prediction (evaluation) is to estimate the value function of an unknown MDP, say $\langle S,A,P,R,\gamma \rangle$. And it includes the Monte-Carlo learning and temporal-difference learning methods.</p><h2 id="Monte-Carlo-Reinforcement-learning"><a href="#Monte-Carlo-Reinforcement-learning" class="headerlink" title="Monte-Carlo Reinforcement learning"></a>Monte-Carlo Reinforcement learning</h2><p>As a famous stochastic simulation method, MC methods plays an important role in a wide range of scientific problems. In reinforcement learning, MC-based methods learn directly from episodes of experience, say a whole observing trajectory.</p><ul><li>Model-free: have no prior knowledge of MDP transitions/ rewards.</li><li>Value = average <strong>sample</strong> returns<ul><li>i.e., use arithmetic mean to replace the real expectation</li></ul></li><li>Requirement of applying MC: all episodes <strong>must terminate</strong></li></ul><h3 id="Description"><a href="#Description" class="headerlink" title="Description"></a>Description</h3><ul><li><p>Goal: learn latent(real) value function $v_\pi$ <strong>from episodes</strong> of experience under policy $\pi$</p></li><li><p>Originally, the return at time $t$(also, state $s$) is the total discounted $\gamma$ rewards:</p><ul><li>$G_t = R_{t+1} + \dots + \gamma^{T-t-1}R_T$</li></ul></li><li><p>And corresponding value function is the <strong>expected return</strong>:</p></li></ul><script type="math/tex; mode=display">v_\pi(s) = \mathbb{E}_\pi [G_t|S_t=s]</script><h3 id="Algorithm-First-visit-MC-policy-evaluation"><a href="#Algorithm-First-visit-MC-policy-evaluation" class="headerlink" title="Algorithm: First-visit MC policy evaluation"></a>Algorithm: First-visit MC policy evaluation</h3><p>The MC algorithm for prediction is to evaluate each state $s$ given policy $\pi$. Here, the first-visit MC is introduced, which means we only take account of the <strong>first time-step $t$</strong> that state $s$ is visit in some episode. We simply count the appearing times with its return $S(s)$, where we compute the return(adding dicounted rewards along the trajectory). Then estimate the value by $V(s) = S(s)/N(s)$. By law of large numbers,</p><script type="math/tex; mode=display">V(s) \to v_\pi(s) ~ as ~ N(s) \to \infty</script><p><img src="fvmc.png" alt="alt fvmc"></p><h3 id="Every-visit-Monte-Carlo-Policy-Evaluation"><a href="#Every-visit-Monte-Carlo-Policy-Evaluation" class="headerlink" title="Every-visit Monte-Carlo Policy Evaluation"></a>Every-visit Monte-Carlo Policy Evaluation</h3><p>Another way to consider is that every time-step t that state s is visited in an episode. We will also obtain the results.</p><h3 id="Incremental-Mean"><a href="#Incremental-Mean" class="headerlink" title="Incremental Mean"></a>Incremental Mean</h3><p>If we rewrite the mean as :</p><script type="math/tex; mode=display">\mu_k = {1\over k}\sum_{j=1}^k x_j = \mu_{k-1} + {1\over k}(x_k - \mu_{k-1})</script><p>Then the update form can be changed into:</p><p>$N(S_t) := N(S_t) + 1$</p><p>$V(S_t) := V(S_t) + {1\over N(S_t)}(G_t - V(S_t))$</p><p>which is the increment Monte-Carlo Updates.</p><p>In non-stationary problems, where episodes may not provide “consistent” information, it can be useful to track a runing mean, i.e. forget old episodes.</p><p>$V(S_t) := V(S_t) + \alpha (G_t - V(S_t))$</p><h2 id="Temporal-Difference-learning"><a href="#Temporal-Difference-learning" class="headerlink" title="Temporal-Difference learning"></a>Temporal-Difference learning</h2><ul><li>Model-free also</li><li>Learning from incomplete episodes, by bootstrapping(update involving estimate)</li><li>Updates a guess towards a guess!</li></ul><h3 id="The-difference-between-TD-and-MC"><a href="#The-difference-between-TD-and-MC" class="headerlink" title="The difference between TD and MC"></a>The difference between TD and MC</h3><p>Take Incremental every-visit MC for example,</p><p>We update value $V(S_t)$ toward actual return $G_t$ as :</p><script type="math/tex; mode=display">V(S_t) := V(S_t) + \alpha (G_t - V(S_t))</script><p>In $TD(0)$ — simplest TD algorithm, we replace the $G_t$ with a guess:</p><script type="math/tex; mode=display">V(S_t) := V(S_t) + \alpha (R_{t+1}+\gamma V(S_{t+1}) - V(S_t))</script><p>where $R_{t+1}+\gamma V(S_{t+1})$ is called the <strong>TD target</strong>; $R_{t+1}+\gamma V(S_{t+1}) - V(S_t)$ is called the <strong>TD error</strong>.</p><p>And the rest of algorithm is similar.</p><h3 id="Algorithm-TD-0-for-estimating-v-pi"><a href="#Algorithm-TD-0-for-estimating-v-pi" class="headerlink" title="Algorithm: TD(0) for estimating $v_\pi$"></a>Algorithm: TD(0) for estimating $v_\pi$</h3><p><img src="td.png" alt="alt td"></p><h3 id="Remarks-of-TD"><a href="#Remarks-of-TD" class="headerlink" title="Remarks of TD"></a>Remarks of TD</h3><ul><li>return $G_t = R_{t+1} + \dots + \gamma^{T-t-1}R_T$ is <strong>unbiased estimate</strong> of $v_\pi(S_t)$</li><li>true TD target (over $v_\pi$), $R_{t+1}+\gamma v_\pi(S_{t+1}$ is also unbiased estimate of $v_\pi(S_t)$</li><li>whileTD target (over $v_\pi$), $R_{t+1}+\gamma v_\pi(S_{t+1}$ is also biased estimate</li><li>TD target has much lower variance than the return</li><li>however, TD target estimate has bias;<ul><li>MC has better convergence properties</li></ul></li></ul><p>Note that:</p><ul><li>MC is not very sensitive to initial value</li><li>TD is more <strong>sensitive</strong></li></ul><h2 id="Batch-MC-and-TD"><a href="#Batch-MC-and-TD" class="headerlink" title="Batch MC and TD"></a>Batch MC and TD</h2><p>If we only have finite observation data, say $K$ episodes totally:</p><script type="math/tex; mode=display">s_1^1, a_1^1, r_2^1 \dots, s_{T_1}^1</script><script type="math/tex; mode=display">\vdots</script><script type="math/tex; mode=display">s_1^K, a_1^K, r_2^K \dots, s_{T_1}^K</script><p>Then we can <strong>repeatedly sample episode</strong> $k\in [1,K]$ and apply MC or TD(0) to episode k. It still works good!</p><p>For certainty equivalence, we can prove that the batch MC or TD:</p><ol><li>MC converges to solution with <strong>minimum mean-squared error</strong>(MSE), and best fit to the <strong>observed returns</strong>:</li></ol><script type="math/tex; mode=display">\sum_{k=1}^K \sum_{t=1}^{T_k} (G_t^k - V(s_t^k))^2</script><ol><li>TD converges to solution of <strong>maximum likelihood Markov model</strong>, and solution to the MDP model $\langle S,A,P,R,\gamma \rangle$ best fits the observed data, say sequence.( common MLE )</li></ol><script type="math/tex; mode=display">P^a_{s,s'} = {1\over N(s,a)} \sum_{k=1}^K \sum_{t=1}^{T_k} 1 \{s_t^k,a_t^k,s_{t+1}^k = s,a,s'\}</script><script type="math/tex; mode=display">R_s^a = {1\over N(s,a)}\sum_{k=1}^K \sum_{t=1}^{T_k} 1\{s_t^k,a_t^k = s,a\} r_t^k</script><h2 id="Summary-and-comparison"><a href="#Summary-and-comparison" class="headerlink" title="Summary and comparison"></a>Summary and comparison</h2><p>Generally speaking, TD <strong>exploits Markov property</strong> (one-step determination) and usually more <strong>efficient in Markov env</strong>; while MC does not exploit and is usually used in non-Markov env.</p><h3 id="Diagram-explanation"><a href="#Diagram-explanation" class="headerlink" title="Diagram explanation"></a>Diagram explanation</h3><ul><li>For Monte-Carlo: $V(S_t) := V(S_t) + \alpha (G_t - V(S_t))$</li></ul><p><img src="mctree.png" alt="alt mctree"></p><ul><li>For Temporal-Difference: $V(S_t) := V(S_t) + \alpha (R_{t+1}+\gamma V(S_{t+1}) - V(S_t))$</li></ul><p><img src="tdtree.png" alt="alt tdtree"></p><ul><li>Also, here is how Dynamic Programming algorithm works:</li></ul><p><img src="dptree.png" alt="alt dptree"></p><hr><p><strong>Reference</strong>: <a href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html" target="_blank" rel="noopener">Teaching slides</a> of Prof. David Silver at UCL</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Model-free prediction (evaluation) is to estimate the value function of an unknown MDP, say $\langle S,A,P,R,\gamma \rangle$. And it incl
      
    
    </summary>
    
    
      <category term="Computer-science" scheme="http://jaredlujr.github.io/categories/computer-science/"/>
    
    
      <category term="Machine-learning" scheme="http://jaredlujr.github.io/tags/machine-learning/"/>
    
      <category term="Reinforcement-learning" scheme="http://jaredlujr.github.io/tags/reinforcement-learning/"/>
    
      <category term="Monte-Carlo" scheme="http://jaredlujr.github.io/tags/monte-carlo/"/>
    
  </entry>
  
  <entry>
    <title>Generating Function</title>
    <link href="http://jaredlujr.github.io/2020/04/01/genefunction/"/>
    <id>http://jaredlujr.github.io/2020/04/01/genefunction/</id>
    <published>2020-04-01T11:37:09.000Z</published>
    <updated>2020-04-07T12:18:52.028Z</updated>
    
    <content type="html"><![CDATA[<p>A series of numbers shared similar features, can often be described as coefficients of some function expansion. Then we will call such function the <strong>generating function</strong>.</p><h2 id="generating-Function"><a href="#generating-Function" class="headerlink" title="generating Function"></a>generating Function</h2><p>In order to obtain a sequence ${a_k: k \geq 0}$, we can represent it by a power series:</p><script type="math/tex; mode=display">g(x) = \sum_{i=0}^\infty a_k x^k = a_0 + a_1 x + a_2 x^2 + \dots</script><p>If such representation holds, then the analysis of such sequence( often only for specific term of such sequence ) can now be changed into the analysis of its generating function.</p><h3 id="Straightforward-example"><a href="#Straightforward-example" class="headerlink" title="Straightforward example"></a>Straightforward example</h3><ol><li>Given $n$, the coefficients of binomial have the form:</li></ol><script type="math/tex; mode=display">\sum_{i=0}^\infty \binom{n}{k} x^k = (1+x)^n</script><ol><li>$k$-ary repeatable combination over $n$-ary set, i.e., to select $k$ elements from $n$ different ones when repetition is allowed; or the number of non-negative integer solutions to equation $x_1+\dots + x_n = k$:</li></ol><script type="math/tex; mode=display">\left( \binom{n}{k}\right) = \binom{n+k-1}{k}</script><script type="math/tex; mode=display">g(x) = (1-x)^{-n} =\sum_{i=0}^\infty \left( \binom{n}{k}\right) x^k</script><p>Hint: consider the generating process of term $x^k$ and what the number $\left( \binom{n}{k}\right) = \binom{n+k-1}{k}$ describes.</p><ol><li>Constrained diophantine equation</li></ol><p>Similar to $case 2$, write the expansion series as polynomial or incomplete series.</p><p>In general, to select $k$ elements from $n$-ary set where the number of element $a_i$ is constrained as set $M_i$. The number of such combinations is denoted as $c_k$, then its generating function is:</p><script type="math/tex; mode=display">g(x) = (1-x)^{-n} =\sum_{i=0}^\infty c_k x^k = \prod_{i=1}^n \left( \sum_{m\in M_i} x^m \right)</script><p>By detailedly observing the form of the R.H.S. above, it makes total sense as an enumeration.</p><p>Many cases from this pattern can construct one-to-one with a lot of counting problems.</p><h3 id="Exponential-generating-function"><a href="#Exponential-generating-function" class="headerlink" title="Exponential generating function"></a>Exponential generating function</h3><p>There is a useful type of generating function as exponential generating function. The only difference with general form above is the factorial denominator $k!$.</p><p>Exponential generating function is introduced to solve <strong>permutation counting problem.</strong> It has the following general form:</p><script type="math/tex; mode=display">\sum_{i=0}^n a_k \frac{x^k}{k!} = a_0 + a_1 x + a_2 x^2 + \dots</script><ol><li>The $k$-ary unrepeatable permutations of $n$-ary set is $(n)_k$, and</li></ol><script type="math/tex; mode=display">\sum_{i=0}^n (n)_k \frac{x^k}{k!} = (1+x)^n</script><ol><li>common Exp generatingf function</li></ol><ul><li>$\{a_k=1, k \geq 0\}$ —- $e^x$;</li><li>$\{a_k=(-1)^k, k \geq 0\}$ —- $e^{-x}$;</li><li>$\{a_k={k!}, k \geq 0\}$ —- $1\over 1-x$;</li></ul><ol><li>To make $k$-ary permutation from $n$-ary set $S=\{ b_1,b_2,\dots, b_n\}$ where the number of element $b_i$ is constrained as set $M_i, m_i\in M_i$. The number of such combinations is denoted as $p_k$, then its generating function is:</li></ol><script type="math/tex; mode=display">\sum_{i=0}^\infty p_k {x^k\over k!} = \prod_{i=1}^n \left( \sum_{m\in M_i} {x^m\over m!} \right)</script><p>where the coefficient of $x_k\over k!$ is</p><script type="math/tex; mode=display">\sum_{m1+\dots+m_n=k, m_i \in M_i} \frac{k!}{m_1!\dots m_n!}</script><p>In particular, if $M_i = \mathbb{N_0}$, then the exponential generating function is $(\sum_{j=0}^\infty \frac{x^j}{j!})^n = e^{nx}$, which is equivalent to that of $n^k$:</p><script type="math/tex; mode=display">\sum_{i=0}^\infty n^k {x^k\over k!}</script><h3 id="Allocation-problem"><a href="#Allocation-problem" class="headerlink" title="Allocation problem"></a>Allocation problem</h3><p>In fact, there exists an one-to-one between permutation and allocation: $k$-ary repeatable permutation is equivalent to the allocation of $k$ distinguishable balls into $n$ distinguishable boxes. We may also add some constraints to the two primal problems to make it more complex.</p><h3 id="Exp-generating-function-of-Stirling-numbers"><a href="#Exp-generating-function-of-Stirling-numbers" class="headerlink" title="Exp. generating function of Stirling numbers"></a>Exp. generating function of Stirling numbers</h3><p><strong>Prop1</strong><br>The exponential generating function of Stirling numbers of 2nd kind:</p><script type="math/tex; mode=display">\sum_{n=0}^\infty S(n,k) \frac{x^n}{n!} = {1\over k!}(e^x -1 )^k</script><p><strong>Corollary1</strong></p><script type="math/tex; mode=display">S(n,k) = {1\over k!} \sum_{i=0}^k (-1)^i \binom{k}{i} (k-i)^n</script><p>Correspondingly, we have the form for 1st kind Stirling.</p><p><strong>Prop2</strong><br>The exponential generating function of Stirling numbers of 2nd kind:</p><script type="math/tex; mode=display">\sum_{n=0}^\infty s(n,k) \frac{x^n}{n!} = {1\over k!}(ln(x+1) )^k</script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;A series of numbers shared similar features, can often be described as coefficients of some function expansion. Then we will call such fu
      
    
    </summary>
    
    
      <category term="Math" scheme="http://jaredlujr.github.io/categories/math/"/>
    
    
      <category term="Combinatorics" scheme="http://jaredlujr.github.io/tags/combinatorics/"/>
    
      <category term="Generating function" scheme="http://jaredlujr.github.io/tags/generating-function/"/>
    
      <category term="Counting" scheme="http://jaredlujr.github.io/tags/counting/"/>
    
  </entry>
  
  <entry>
    <title>Note of SVM-(4)</title>
    <link href="http://jaredlujr.github.io/2020/03/31/svm4/"/>
    <id>http://jaredlujr.github.io/2020/03/31/svm4/</id>
    <published>2020-03-31T13:05:37.000Z</published>
    <updated>2020-04-01T13:59:50.442Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Soft-Margin-non-separable-dataset"><a href="#Soft-Margin-non-separable-dataset" class="headerlink" title="Soft Margin: non-separable dataset"></a>Soft Margin: non-separable dataset</h2><p>SVM works with a prerequisite that the given dataset is linearly separable. Even the kernel trick provides an incredible approach to help increase the likelihood that that data is separable, but not always does. Generally, a speck of noise samples, say outliers, will fail the SVM due to its hard requirement $y^{(i)}(w^T x^{(i)} + b) \geq 1$. In order to improve this, we introduce the regularized (slacking) term $\xi_i$, such that the problem has changed into:</p><script type="math/tex; mode=display">\min_{w,b} {1\over 2} ||w||^2 + C \sum_{i=1}^m \xi_i</script><script type="math/tex; mode=display">s.t. \; y^{(i)} (w^Tx^{(i)} + b ) \geq 1- \xi_i,</script><script type="math/tex; mode=display">\xi_i\geq 0,  i =1,2,\dots,m</script><p>On top of that, examples are now permitted to have (functional) margin less than $1$. However, the “permission” will add extra penalty to the objective function by $C\xi_i$, which is a trade-off.</p><p>We can form the Lagrangian:</p><script type="math/tex; mode=display">L(w,b,\xi,\alpha,r) = {1\over 2} ||w||^2 + {C\over 2} \sum_{i=1}^m \xi_i^2 - \sum_{i=1}^m \alpha_i [y^{(i)}(w^T x^{(i)} + b) - 1 + \xi_i] -\sum_{i=1}^m r_i \xi_i</script><p>where $\alpha_i, r_i$ are the Lagrange multipliers.</p><p>The dual form of the problem:</p><script type="math/tex; mode=display">\max_\alpha W(\alpha) = \sum_{i=1}^m \alpha_i  - {1\over 2} \sum_{i=1}^{m} \sum_{j=1}^m \alpha_i \alpha_j y_i y_j K(x_i, x_j)</script><script type="math/tex; mode=display">s.t. \; 0 \leq \alpha_i \leq C, i=1,\dots,m</script><script type="math/tex; mode=display">\sum_{i=1}^m \alpha_iy^{(i)} = 0</script><p>By solving which, we can also obtain the optimal classifier like what we do in the linear separable scenario.</p><p><strong>Remarks</strong>:</p><ul><li>$C$, as the penalty factors, is a hyperparameter in SVM. It indicate the measure of the penalty of wrongly classified samples;</li><li>When $C$ increase, the contribution from wrongly classified samples will flood the primal objective, thus “caring the noises” too much, which is inclined to overfit.<ul><li>If $C$ goes to $\infty$, then it recovers to the hard margin: now we build the hyperplane <strong>along the contour of the “real” boundary</strong>.</li><li>If $C$ approaches $0$, it confines the $\alpha_i$ too hard around $0$ and ignores the outliers.</li></ul></li><li>Now the minimize of objective include:<ul><li>maximize the margin (w.r.t $w$)</li><li>minimize the number of wrongly classified points</li></ul></li></ul><h2 id="SMO-algorithm"><a href="#SMO-algorithm" class="headerlink" title="SMO algorithm"></a>SMO algorithm</h2><h3 id="Coordinate-ascent"><a href="#Coordinate-ascent" class="headerlink" title="Coordinate ascent"></a>Coordinate ascent</h3><p>Introduce by John Platt, SMO (sequential minimal optimization) algorithm gives an efficient way of solving the dual problem. It mainly focuses on how we utilize the samples to update the parameters.</p><p>Consider the following unconstrained optimization problem:</p><script type="math/tex; mode=display">\max_\alpha W(\alpha_1,\dots,\alpha_m)</script><p>The SMO algorithm uses so-called <strong>coordinate ascent</strong> to finish the update:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Loop until convergence:&#123;</span><br><span class="line">  For i &#x3D; 1,...,m&#123;</span><br><span class="line">    ai :&#x3D; argmax_ai W(a1,...,ai-1,a^i,ai+1,...,am)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>In the inner loop, we hold all the variables fixed except for some $\alpha_i$, and re-optimize $W$ w.r.t just the parameters $\alpha_i$.</p><p><img src="ca.png" alt="alt ca"></p><h3 id="SMO"><a href="#SMO" class="headerlink" title="SMO"></a>SMO</h3><p>Coordinate ascent gives a powerful tools for update the parameters, but it fails for most constrained problems like our dual optimization problems due to the equality.</p><script type="math/tex; mode=display">\max_\alpha W(\alpha) = \sum_{i=1}^m \alpha_i  - {1\over 2} \sum_{i=1}^{m} \sum_{j=1}^m \alpha_i \alpha_j y_i y_j K(x_i, x_j)</script><script type="math/tex; mode=display">s.t. \; 0 \leq \alpha_i \leq C, i=1,\dots,m</script><script type="math/tex; mode=display">\sum_{i=1}^m \alpha_iy^{(i)} = 0</script><p>However, by altering a bit, we can let it work greatly on the SVM problem. In order not to violate the condition $\sum_{i=1}^m \alpha_iy^{(i)} = 0$, we may update two parameters at the same time:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Repeat till convergence &#123;</span><br><span class="line">  1. Select some pair ai and aj to update next (using a</span><br><span class="line">     heuristic that tries to pick the two that will allow us to</span><br><span class="line">      make the biggest progress towards the global maximum).</span><br><span class="line">  2. Reoptimize W(a) with respect to ai and aj, while holding</span><br><span class="line">   all the other ak’s (k ̸&#x3D; i, j) fixed.</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Compared to the coordinate ascent, we instead hold $\alpha_3,\dots,\alpha_m$ fixed and re-optimize $W$ w.r.t $\alpha_1, \alpha_2$:</p><script type="math/tex; mode=display">\alpha_1 y_1+\alpha_2 y_2 = \zeta</script><script type="math/tex; mode=display">0 \leq \alpha_1 \leq C</script><script type="math/tex; mode=display">0 \leq \alpha_2 \leq C</script><h3 id="Hinge-loss-function"><a href="#Hinge-loss-function" class="headerlink" title="Hinge loss function"></a>Hinge loss function</h3><p>Let’s look back to the primal optimization problem. We can interpret the linear SVM in another way, to minimize the following (loss) objective funtion:</p><script type="math/tex; mode=display">\sum_{i=1}^m [1- y^{(i)}(w^T x^{(i)} + b )]_+ \lambda ||w||^2</script><p>where $[z]_+$ is called hinge loss function, which is defined as:</p><script type="math/tex; mode=display">[z]_+=\begin{cases}z, & \text{ z > 0}\\0 & \text{otherwise}\end{cases}</script><p>This is to say, if given sample is correctly classified and has margin larger than $1$, the loss will be zero; on the contrary, it will be $1- y^{(i)}(w^T x^{(i)} + b)$.</p><p>The second term $\lambda ||w||^2$ is the $l_2$ regularized term.</p><p><img src="lossf.png" alt="alt lossf"></p><p>From the figure above, we can see that hinge loss function is one of the continuous upper bound of $0-1$ loss. The logistic loss function decreases after the $1$, which means giving regard to <strong>every samples</strong> even they are far away from the decision boundary.</p><p>$0-1$ loss function in fact exhibits the “real loss” but its uncontinuity gives rise to the difficulty for update.</p><hr><p><strong>Reference</strong>:<br><a href="http://cs229.stanford.edu/notes/cs229-notes3.pdf" target="_blank" rel="noopener">Stanford CS229-note3</a> by Andrew Ng<br>Statistical Learning methods, by Li Hang (2012)</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Soft-Margin-non-separable-dataset&quot;&gt;&lt;a href=&quot;#Soft-Margin-non-separable-dataset&quot; class=&quot;headerlink&quot; title=&quot;Soft Margin: non-separable
      
    
    </summary>
    
    
      <category term="Computer-science" scheme="http://jaredlujr.github.io/categories/computer-science/"/>
    
    
      <category term="Machine-learning" scheme="http://jaredlujr.github.io/tags/machine-learning/"/>
    
      <category term="Support-vector-machine" scheme="http://jaredlujr.github.io/tags/support-vector-machine/"/>
    
      <category term="SVM" scheme="http://jaredlujr.github.io/tags/svm/"/>
    
  </entry>
  
  <entry>
    <title>Introduction to Subgroup</title>
    <link href="http://jaredlujr.github.io/2020/03/30/subgroup/"/>
    <id>http://jaredlujr.github.io/2020/03/30/subgroup/</id>
    <published>2020-03-30T01:41:30.000Z</published>
    <updated>2020-03-30T04:10:11.449Z</updated>
    
    <content type="html"><![CDATA[<p>An important concept in the group theory is the <strong>Subgroup</strong>. As part of a given group, its subgroup holds the algebra structure and has a close relation to the original group.</p><h2 id="Introduction-to-subgroup-with-relevant-concepts"><a href="#Introduction-to-subgroup-with-relevant-concepts" class="headerlink" title="Introduction to subgroup with relevant concepts"></a>Introduction to subgroup with relevant concepts</h2><h3 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h3><p>Let $(G,~\cdot)$ be a group and $H$ is a non-empty subset of it. If the $\cdot$ is closed operation in $H$, then $(H,~\cdot)$ also forms a group, and called subgroup of $G$. We denote this relation as $H \leq G$.</p><p>Remarks:</p><ul><li>Group $G$ always conceives subgroups<ul><li>at least $G$ itself and $\{e\}$, which are called <strong>trivial subgroup</strong> of $G$</li><li>except for $G$, any subgroup of $G$ is called proper subgroup(like proper set)</li></ul></li></ul><h3 id="Propsition"><a href="#Propsition" class="headerlink" title="Propsition"></a>Propsition</h3><h4 id="Shared-inverse-and-identity-element"><a href="#Shared-inverse-and-identity-element" class="headerlink" title="Shared inverse and identity element"></a>Shared inverse and identity element</h4><p><strong>Prop1</strong> Any subgroup $H$ shares the identity element $e$ with $G$; any elements $h\in H$ has the same inverse element in $H$ as in $G$.</p><h4 id="Equivalent-statement"><a href="#Equivalent-statement" class="headerlink" title="Equivalent statement"></a>Equivalent statement</h4><p><strong>Prop2</strong> $H$, a non-empty subset of group $G$, is subgroup if and only if: $\forall a,b \in H$, then $ab^{-1} \in H$.</p><p><strong>Variant</strong> Let $ H \subset G, H \leq G \Leftrightarrow HH^{-1} = H$</p><h3 id="Subset-generated-subgroup"><a href="#Subset-generated-subgroup" class="headerlink" title="Subset-generated subgroup"></a>Subset-generated subgroup</h3><p><strong>Def</strong> Let $G$ be group, and $M$ is its subset. The least subgroup containing $M$, called <em>subgroup generated by $M$</em>, is denoted as $\langle M \rangle$; correspondingly, we name $M$ the <em>generating set</em> of $\langle M \rangle$.</p><ul><li>In particular, when $M$ contains only a single element $m$, then $\langle M \rangle$ is called <strong>cyclic group</strong>.<ul><li>For instance, $\mathbb Z$ can be seen as $1$-generated infinitecyclic group; $\mathbb Z_n$, the multiplicative group of integers modulo $n$, is generated by $\bar 1$ with order $n$.</li><li>Essentially, any cyclic group is isomorphic with one of them.</li></ul></li></ul><h3 id="The-order-of-element-in-group"><a href="#The-order-of-element-in-group" class="headerlink" title="The order of element in group"></a>The order of element in group</h3><p><strong>Def</strong> Let $a\in G$ be an element in group $G$. The least positive number $m$ rendering $a^m = e$ is called the order of $a$, which is denoted as $o(a)$.</p><p>Remarks:</p><ul><li>$o(a) = 1$ if and only if $a=e$</li><li>inverse element $a^{-1} =  a^{n-1}$</li><li>if $o(a) = \infty$, then $ m \neq s \Leftrightarrow a^m \neq a^s$</li></ul><h4 id="Property"><a href="#Property" class="headerlink" title="Property"></a>Property</h4><p><strong>Property 1</strong></p><script type="math/tex; mode=display">a^n = e \Rightarrow o(a)~|~n</script><p><strong>Property 2</strong></p><script type="math/tex; mode=display">o(a)< \infty, ~ o(a) ~ | ~|G|</script><p><strong>Property 3</strong></p><script type="math/tex; mode=display">o(a) < \infty, ~ o(a^t) = \frac{o(a)}{(t,o(a))}</script><p><strong>Property 4</strong></p><p>If $ o(a) = m &lt;\infty, o(b) = n &lt; \infty$, and $ab=ba$, $gcd(m,n)=1$, then $o(ab)=mn$</p><ul><li><em>Corollary1</em>: $o(a) = st \Rightarrow o(a^s) = t, (s,t\in \mathbb N_+)$</li><li><em>Corollary2</em>: $o(a) = n$, then $o(a^k) =n \Leftrightarrow gcd(k,n)=1$</li></ul><p>Remarks:</p><ul><li><p>In order to prove $o(a) = n$, we may prove $o(a)|n$ and $n|o(a)$</p></li><li><p>When solving divisible problem, we can write any number as $m=qn+r$</p></li></ul><h3 id="Common-notation-Descartes-product-of-subgroup"><a href="#Common-notation-Descartes-product-of-subgroup" class="headerlink" title="Common notation: (Descartes) product of subgroup"></a>Common notation: (Descartes) product of subgroup</h3><p>Let $H,K$ be subsetsof group $G$, then we denote:</p><script type="math/tex; mode=display">HK = \{hk,h\in H,k\in k\}</script><script type="math/tex; mode=display">H^{-1}=\{h^{-1}, h\in H\}</script><script type="math/tex; mode=display">aK = \{ak,k\in k\}, a\in G</script><p>Remarks:</p><ul><li>Not an one-to-one, we only require the existence</li><li>If $H$ is a group, then $H=H^{-1}$</li></ul><h4 id="Propsition-1"><a href="#Propsition-1" class="headerlink" title="Propsition"></a>Propsition</h4><p>Let $H,K$ be subgroups of $G$, then</p><script type="math/tex; mode=display">HK \leq G \Leftrightarrow HK = KH</script><h3 id="Common-types-of-subset"><a href="#Common-types-of-subset" class="headerlink" title="Common types of subset"></a>Common types of subset</h3><h4 id="The-Center-of-group"><a href="#The-Center-of-group" class="headerlink" title="The Center of group"></a>The Center of group</h4><p><strong>Def</strong> Let G be group, then the following subgroup</p><script type="math/tex; mode=display">C(G) = \{g\in G | gx=xg, \forall x \in G\}</script><p>is called the center of G.</p><p>Remarks:</p><ul><li>$C(G)$ is the collection of those which are exchangable with any elements in $G$</li><li>At least $e \in C(G)$</li><li>If $C(G) = G$, then $G$ is Abel Group</li><li>The order of $C(G)$ gives a measure of $G$’s exchangeability</li><li>Any subgroup $H$ of $G$, satisfies $HC(G) = C(G)H$</li></ul><h4 id="Centralizer"><a href="#Centralizer" class="headerlink" title="Centralizer"></a>Centralizer</h4><p><strong>Def</strong> Let $a\in G$, then subgroup</p><script type="math/tex; mode=display">C_G(a) = \{g\in G | ga = ag\}</script><p>is called the <strong>centralizer</strong> of $a$ in $G$, immediately we also have:</p><script type="math/tex; mode=display">C(G) = \bigcap_{a\in G} C_G(a)</script><p>(The centralizer of $a$ is a collection of those are exchangable with $a$ in $G$.)</p><p><strong>Property</strong></p><script type="math/tex; mode=display">|G| = \sum_{a\in C(G)} \frac{|G|}{|C_G(a)|} + \sum_{a\notin C(G)} \frac{|G|}{|C_G(a)|}</script><p>( <em>The first term: if $a\in C(G)$, then $C_G(a) = G$, so that $\sum 1$ -&gt; the order of center</em> )</p><h4 id="Normalizer-and-normal-subgroup"><a href="#Normalizer-and-normal-subgroup" class="headerlink" title="Normalizer and normal subgroup"></a>Normalizer and normal subgroup</h4><p><strong>Def</strong> Let subset $A \subset G$, then subgroup</p><script type="math/tex; mode=display">N_G(A) = \{g\in G | gA = Ag\}</script><p>is called the <strong>normalizer</strong> of set $A$ in $G$.</p><p><strong>Def</strong> Let $G$ be group, $N \leq G$, if:</p><script type="math/tex; mode=display">gN=Ng, \forall g \in G</script><p>or equivalently,</p><script type="math/tex; mode=display">gNg^{-1} = N, \forall g \in G</script><p>Then $N$ is the normal subgroup of $G$, denoted as  $N \triangleleft G$</p><p>(Corresponding to center, here we only require the <strong>existence</strong> of exchange result.)</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;An important concept in the group theory is the &lt;strong&gt;Subgroup&lt;/strong&gt;. As part of a given group, its subgroup holds the algebra struc
      
    
    </summary>
    
    
      <category term="Math" scheme="http://jaredlujr.github.io/categories/math/"/>
    
    
      <category term="Group-theory" scheme="http://jaredlujr.github.io/tags/group-theory/"/>
    
      <category term="Group" scheme="http://jaredlujr.github.io/tags/group/"/>
    
  </entry>
  
  <entry>
    <title>Policy iteration by dynamic programming</title>
    <link href="http://jaredlujr.github.io/2020/03/29/policy-iteration/"/>
    <id>http://jaredlujr.github.io/2020/03/29/policy-iteration/</id>
    <published>2020-03-29T15:14:53.000Z</published>
    <updated>2020-03-29T16:22:13.564Z</updated>
    
    <content type="html"><![CDATA[<p>There is a straightforward method to help agent solve the optimal policy and the idea behind is dynamic programming(DP).</p><h2 id="What-is-Dynamic-Programming"><a href="#What-is-Dynamic-Programming" class="headerlink" title="What is Dynamic Programming?"></a>What is Dynamic Programming?</h2><ul><li>A method for solving complex problem</li><li>By breaking down into subproblems<ul><li>solve the subproblems bit by bit</li><li>combine all solutions to subproblems</li></ul></li></ul><p>However, not every best solution can be found by DP, and two properties are required:</p><ul><li>Optimal substructure<ul><li>prerequisite for decomposition</li></ul></li><li>Overlapping subproblems<ul><li>subproblems recur many times</li><li>solution can be <strong>cached and reused</strong></li></ul></li></ul><p>Luckily, the <a href="https://jiaruilu.com/2020/03/20/2020-03-20-mdp" target="_blank" rel="noopener">Markov decision process(MDP)</a> satisfy both properties:</p><ul><li>Bellman equation give <strong>recursive decomposition</strong></li><li>Value function <strong>stores and reuses solutions</strong></li></ul><p>In the rest of sections, we will talk about how the solution is obtained through iterations. It looks just as simple as fix-point iteration.</p><p>Classified by our application purpose, the DP algorithm can basically have two forms:</p><ul><li>For prediction (policy evalution):<ul><li>Input: MDP $\langle S,A,P,R,\gamma \rangle$, policy $\pi$ or MRP $\langle S,P^\pi,R^\pi,\gamma \rangle$</li><li>Output: value function given $\pi$, v_\pi</li></ul></li><li>For control(optimization):<ul><li><ul><li>Input: MDP $\langle S,A,P,R,\gamma \rangle$</li></ul></li><li>Output: optimal value function v_\ast and optimal policy $\pi$</li></ul></li></ul><h2 id="Policy-Evaluation"><a href="#Policy-Evaluation" class="headerlink" title="Policy Evaluation"></a>Policy Evaluation</h2><ul><li>Problem: evaluate a given policy $\pi$</li><li>Solution: iterative application of Bellman expectation backup</li><li>Routine: $v_1\to v_2 \to \dots \to v_\pi$(end)</li><li>Synchronous backups: $k+1$-stage only use $k$-stage information</li><li>Iterative for each state in one update cycle</li><li>Converge to $v_\pi$ <em>(can be proved)</em></li></ul><h3 id="On-the-basis-of…-Bellman-equation"><a href="#On-the-basis-of…-Bellman-equation" class="headerlink" title="On the basis of… Bellman equation"></a>On the basis of… Bellman equation</h3><p><img src="be-diagram.png" alt="alt be"></p><h3 id="Algorithm-description"><a href="#Algorithm-description" class="headerlink" title="Algorithm description"></a>Algorithm description</h3><p><img src="policydp-algo1.png" alt="alt algo1"></p><h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><p>Suppose there is a $4\times4$ grid with two terminals. And we will “help” agent to evaluate the current decision policy, which is described by converged value function.</p><p><img src="dp-iter.png" alt="alt iter"></p><p>When $k=1$, we will use the value function from $k=0$.</p><h2 id="Policy-Improvement"><a href="#Policy-Improvement" class="headerlink" title="Policy Improvement"></a>Policy Improvement</h2><p>On top of the policy evalution, which provides us a effective score for updating the policy to be better.</p><p>Because the policy, the way agent decides its action, is causative relative to the following value, the policy update is actually a optimization problem.</p><p>In short, we can improve the policy by acting greedily:</p><script type="math/tex; mode=display">\pi'(s) = arg\max_{a\in A} q_\pi (s,a)</script><p>Subsequently, this improves the value from any state $s$ over one step,</p><script type="math/tex; mode=display">v_{\pi'} = q_\pi (s,\pi'(s)) \max_{a\in A} q_\pi (s,a) \geq q_\pi (s,a) = v_\pi (s)</script><p>Improvements <strong>stop</strong> if the equality above holds, which also indicates that the Bellman optimality eqation has been satisfied.</p><h3 id="Greedy-selection"><a href="#Greedy-selection" class="headerlink" title="Greedy selection"></a>Greedy selection</h3><ul><li>Given a policy $\pi$<ul><li>evalution of $\pi$ following the last section</li><li>improvement the policy by acting <strong>greedily</strong> w.r.t $v_\pi$</li></ul></li></ul><script type="math/tex; mode=display">\pi' = greedy(v_\pi)</script><ul><li>In general, improved policy is optimal $\pi’ = \pi^\ast$</li><li><p>One-hot strategy</p></li><li><p>Routine: $\pi_0 \to v_{\pi_0} \to \pi_1 \to v_{\pi_1} \to \dots \to \pi_\ast \to \pi_\ast$</p></li></ul><p><img src="policydp-algo2.png" alt="alt algo2"></p><h3 id="Modified-Policy-Iteration"><a href="#Modified-Policy-Iteration" class="headerlink" title="Modified Policy Iteration"></a>Modified Policy Iteration</h3><ul><li>policy evaluation DOES not need to converge to $v_pi$<ul><li>more iteration cause computation waste</li><li>sometimes small iterations can give same results as final one</li></ul></li></ul><p><img src="dp-iter2.png" alt="alt iter"></p><ul><li>instead, set $k=k_0$ as stopping condition</li><li>or $\epsilon$-convergence</li><li>if we update policy EVERY ITERATION…<ul><li>this is equivalent to <strong>value iteration</strong></li></ul></li></ul><h2 id="Value-Iteration"><a href="#Value-Iteration" class="headerlink" title="Value Iteration"></a>Value Iteration</h2><ul><li>Problem: find optimal policy $\pi$</li><li>Solution: iterative application of Bellman <strong>optimality</strong> backup</li><li>Routine: $v_1\to v_2 \to \dots \to v_\pi$(end)</li><li>Synchronous backups: $k+1$-stage only use $k$-stage information</li><li>Iterative for each state in one update cycle</li><li>Converge to $v_\pi$ <em>(can be proved)</em></li><li>Unlike policy iteration, there is NO explicit policy<ul><li>intermediate value functions may not correspond to any policy!</li></ul></li></ul><h3 id="Bellman-Optimality-Backup"><a href="#Bellman-Optimality-Backup" class="headerlink" title="Bellman Optimality Backup"></a>Bellman Optimality Backup</h3><p><img src="boe-diagram.png" alt="alt boe"></p><h3 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm"></a>Algorithm</h3><p><img src="policydp-algo3.png" alt="alt algo3"></p><h3 id="Comparison-between-Synchronous-Dynamic-Programming-Algorithms"><a href="#Comparison-between-Synchronous-Dynamic-Programming-Algorithms" class="headerlink" title="Comparison between Synchronous Dynamic Programming Algorithms"></a>Comparison between Synchronous Dynamic Programming Algorithms</h3><p><img src="comp.png" alt="alt comp"></p><ul><li>All algorithms are based on state-value function $v_\pi(s)$ and $v_\ast (s)$</li><li>Complexity $O(mn^2)$ per iteration, for $m$ actions and $n$ states</li></ul><hr><p><strong>Reference</strong>: <a href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html" target="_blank" rel="noopener">Teaching slides</a> of Prof. David Silver at UCL</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;There is a straightforward method to help agent solve the optimal policy and the idea behind is dynamic programming(DP).&lt;/p&gt;
&lt;h2 id=&quot;What
      
    
    </summary>
    
    
      <category term="Computer-science" scheme="http://jaredlujr.github.io/categories/computer-science/"/>
    
    
      <category term="Machine-learning" scheme="http://jaredlujr.github.io/tags/machine-learning/"/>
    
      <category term="Dynamic-programming" scheme="http://jaredlujr.github.io/tags/dynamic-programming/"/>
    
      <category term="Reinforcement-learning" scheme="http://jaredlujr.github.io/tags/reinforcement-learning/"/>
    
      <category term="Control" scheme="http://jaredlujr.github.io/tags/control/"/>
    
  </entry>
  
  <entry>
    <title>How to use sed in Linux?</title>
    <link href="http://jaredlujr.github.io/2020/03/27/command-sed/"/>
    <id>http://jaredlujr.github.io/2020/03/27/command-sed/</id>
    <published>2020-03-27T14:30:31.000Z</published>
    <updated>2020-04-03T08:30:37.789Z</updated>
    
    <content type="html"><![CDATA[<p><strong>sed</strong> is a streaming text command-line tool in Linux and Mac OS(a little bit different). It can work perfect with RE to finish the operation of one or more than one text file, including delete, replace, insert and so on.</p><h2 id="Patterns"><a href="#Patterns" class="headerlink" title="Patterns"></a>Patterns</h2><h3 id="Command-template"><a href="#Command-template" class="headerlink" title="Command template"></a>Command template</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sed [options] <span class="string">'command'</span> file(s)</span><br><span class="line">sed [options] -f scriptfile file(s)</span><br><span class="line">sed -h : to display the helper doc</span><br></pre></td></tr></table></figure><h3 id="Input-arguments"><a href="#Input-arguments" class="headerlink" title="Input arguments"></a>Input arguments</h3><p>File: filename(s) in system</p><h3 id="Command-parameters"><a href="#Command-parameters" class="headerlink" title="Command parameters"></a>Command parameters</h3><p>(<em>frequently used ones are listed below</em>)<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">a\ <span class="comment"># insert downward, relatively</span></span><br><span class="line">i\ <span class="comment"># insert upward, relatively</span></span><br><span class="line">d  <span class="comment"># delete</span></span><br><span class="line">s  <span class="comment"># replace</span></span><br><span class="line">h  <span class="comment"># copy the content to buffer</span></span><br><span class="line">g  <span class="comment"># use stuffs in buffer to replace</span></span><br></pre></td></tr></table></figure></p><h3 id="Replace-flags"><a href="#Replace-flags" class="headerlink" title="Replace flags"></a>Replace flags</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">g <span class="comment"># all-replace in line</span></span><br><span class="line">p <span class="comment"># print the line</span></span><br><span class="line">w <span class="comment"># write the line into a file</span></span><br><span class="line">x <span class="comment"># swap the text with the buffer</span></span><br></pre></td></tr></table></figure><h3 id="Metacharacter-set"><a href="#Metacharacter-set" class="headerlink" title="Metacharacter set"></a>Metacharacter set</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">^ <span class="comment"># match the beginning of line</span></span><br><span class="line">$ <span class="comment"># match the ending of line</span></span><br><span class="line">. <span class="comment"># match a non-new-line arbitrary character</span></span><br><span class="line">* <span class="comment"># match 0 or more character</span></span><br><span class="line">[] <span class="comment"># match a range of characters</span></span><br><span class="line">[^] <span class="comment"># match characters beyond the range</span></span><br><span class="line">\(..\) <span class="comment"># match substring and keep</span></span><br><span class="line">&amp; <span class="comment"># keep target character and replace the &amp;</span></span><br><span class="line">\&lt; <span class="comment"># match the beginning of word</span></span><br><span class="line">\&gt; <span class="comment"># match the ending of word</span></span><br></pre></td></tr></table></figure><h4 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">/^sed/ <span class="comment"># -&gt; "sedimentation ..."</span></span><br><span class="line">/sed$/ <span class="comment"># -&gt; ".... sed"</span></span><br><span class="line">/s.d/ <span class="comment"># -&gt; "sad"</span></span><br><span class="line">/*sed/ <span class="comment"># -&gt; "    sed"</span></span><br><span class="line">[] <span class="comment"># /[ss]ed/ -&gt; "sed" or "Sed"</span></span><br><span class="line">[^] <span class="comment"># /[^A-RT-Z]ed/ "Sed"</span></span><br><span class="line">\(..\) <span class="comment"># s/\(love\)able/\1rs，loveable -&gt; lovers</span></span><br><span class="line">&amp; <span class="comment"># s/love/ **&amp;** / "love"-&gt; "**love**"</span></span><br><span class="line">\&lt; <span class="comment"># /\&lt;love/ -&gt; "loveable" or "lovelorn"</span></span><br><span class="line">\&gt; <span class="comment"># /love\&gt;/ -&gt; "nolove"</span></span><br></pre></td></tr></table></figure><h2 id="Usage-instances"><a href="#Usage-instances" class="headerlink" title="Usage instances"></a>Usage instances</h2><h3 id="replacing-s"><a href="#replacing-s" class="headerlink" title="replacing: s"></a>replacing: s</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sed <span class="string">'s/book/books/'</span> file</span><br><span class="line"></span><br><span class="line">sed -n <span class="string">'s/test/TEST/p'</span> file <span class="comment"># only matched lines are printed out</span></span><br><span class="line"></span><br><span class="line">sed -i <span class="string">'s/book/books/g'</span> file <span class="comment"># directly editing the files without display</span></span><br></pre></td></tr></table></figure><h3 id="all-replacing-g"><a href="#all-replacing-g" class="headerlink" title="all-replacing: g"></a>all-replacing: g</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">sed <span class="string">'s/book/books/g'</span> file</span><br><span class="line"></span><br><span class="line"><span class="comment"># if we want replacing happens from Nth match</span></span><br><span class="line"><span class="built_in">echo</span> sksksksksksk | sed <span class="string">'s/sk/SK/2g'</span></span><br><span class="line">skSKSKSKSKSK</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> sksksksksksk | sed <span class="string">'s/sk/SK/3g'</span></span><br><span class="line">skskSKSKSKSK</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> sksksksksksk | sed <span class="string">'s/sk/SK/4g'</span></span><br><span class="line">skskskSKSKSK</span><br></pre></td></tr></table></figure><h3 id="delimiter-and-so-on"><a href="#delimiter-and-so-on" class="headerlink" title="delimiter: / : | and so on"></a>delimiter: / : | and so on</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sed <span class="string">'s/test/TEXT/g'</span></span><br><span class="line">sed <span class="string">'s:test:TEXT:g'</span></span><br><span class="line">sed <span class="string">'s|test|TEXT|g'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># escaping when we need their happening</span></span><br><span class="line">sed <span class="string">'s/\/bin/\/usr\/local\/bin/g'</span></span><br></pre></td></tr></table></figure><h3 id="delete-d"><a href="#delete-d" class="headerlink" title="delete: d"></a>delete: d</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">sed <span class="string">'/^$/d'</span> file <span class="comment"># delete empty lines</span></span><br><span class="line"></span><br><span class="line">sed <span class="string">'2d'</span> file <span class="comment"># delete 2nd line</span></span><br><span class="line"></span><br><span class="line">sed <span class="string">'2,$d'</span> file <span class="comment"># delete 2nd line to end</span></span><br><span class="line"></span><br><span class="line">sed <span class="string">'$d'</span> file <span class="comment"># delete end line</span></span><br><span class="line"></span><br><span class="line">sed <span class="string">'/^test/'</span>d file <span class="comment"># delete line with 'test' as beginning</span></span><br></pre></td></tr></table></figure><h3 id="choosing-target-lines"><a href="#choosing-target-lines" class="headerlink" title="choosing target lines: ,"></a>choosing target lines: ,</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sed -n <span class="string">'/test/,/check/p'</span> file <span class="comment"># prints lines from test and check</span></span><br><span class="line"></span><br><span class="line">sed -n <span class="string">'5,/^test/p'</span> file <span class="comment"># print from 5th line to the first line with beginning as 'text'</span></span><br></pre></td></tr></table></figure><h3 id="multiple-command-e"><a href="#multiple-command-e" class="headerlink" title="multiple command: e"></a>multiple command: e</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed -e <span class="string">'1,5d'</span> -e <span class="string">'s/test/check/'</span> file <span class="comment"># perform double operations to each line</span></span><br></pre></td></tr></table></figure><h3 id="write-into-file-w"><a href="#write-into-file-w" class="headerlink" title="write into file: w"></a>write into file: w</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed -n <span class="string">'/test/w outfile'</span> example</span><br></pre></td></tr></table></figure><h3 id="add-downward-a"><a href="#add-downward-a" class="headerlink" title="add(downward): a"></a>add(downward): a</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed <span class="string">'/^test/a\this is a test line'</span> file</span><br></pre></td></tr></table></figure><h3 id="insert-upward-i"><a href="#insert-upward-i" class="headerlink" title="insert(upward): i"></a>insert(upward): i</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed <span class="string">'/^test/i\this is a test line'</span> file <span class="comment"># before the lines with beginning as 'test'</span></span><br></pre></td></tr></table></figure><h3 id="Other-common-usage"><a href="#Other-common-usage" class="headerlink" title="Other common usage"></a>Other common usage</h3><h4 id="keep-matched"><a href="#keep-matched" class="headerlink" title="keep matched"></a>keep matched</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> this is a <span class="built_in">test</span> line | sed <span class="string">'s/\w\+/[&amp;]/g'</span> <span class="comment"># match each word and add brackets</span></span><br><span class="line">[this] [is] [a] [<span class="built_in">test</span>] [line]</span><br><span class="line"></span><br><span class="line">sed <span class="string">'s/^192.168.0.1/&amp;localhost/'</span> file</span><br><span class="line">192.168.0.1localhost</span><br></pre></td></tr></table></figure><h4 id="substring"><a href="#substring" class="headerlink" title="substring"></a>substring</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> this is digit 7 <span class="keyword">in</span> a number | sed <span class="string">'s/digit \([0-9]\)/\1/'</span></span><br><span class="line">this is 7 <span class="keyword">in</span> a number</span><br></pre></td></tr></table></figure><h4 id="combination"><a href="#combination" class="headerlink" title="combination"></a>combination</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sed <span class="string">'pattern'</span> | sed <span class="string">'pattern'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># also as:</span></span><br><span class="line"></span><br><span class="line">sed <span class="string">'pattern; pattern'</span></span><br></pre></td></tr></table></figure><h4 id="quotation"><a href="#quotation" class="headerlink" title="quotation"></a>quotation</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">test</span>=hello</span><br><span class="line"><span class="built_in">echo</span> hello WORLD | sed <span class="string">"s/<span class="variable">$test</span>/HELLO"</span></span><br><span class="line">HELLO WORLD</span><br></pre></td></tr></table></figure><h4 id="next"><a href="#next" class="headerlink" title="next"></a>next</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed <span class="string">'/test/&#123; n; s/aa/bb/; &#125;'</span> file <span class="comment"># if test is matched then perform over the next line</span></span><br></pre></td></tr></table></figure><h4 id="quit-break"><a href="#quit-break" class="headerlink" title="quit(break)"></a>quit(break)</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed <span class="string">'10q'</span> file <span class="comment"># quit sed after print out line 10</span></span><br></pre></td></tr></table></figure><h4 id="print-odd-or-even-lines"><a href="#print-odd-or-even-lines" class="headerlink" title="print odd or even lines"></a>print odd or even lines</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sed -n <span class="string">'p;n'</span> test.txt  <span class="comment">#odd</span></span><br><span class="line">sed -n <span class="string">'n;p'</span> test.txt  <span class="comment">#even</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># method 2</span></span><br><span class="line"></span><br><span class="line">sed -n <span class="string">'1~2p'</span> test.txt  <span class="comment">#odd</span></span><br><span class="line">sed -n <span class="string">'2~2p'</span> test.txt  <span class="comment">#even</span></span><br></pre></td></tr></table></figure><h2 id="Affiliated-tools-under-shell"><a href="#Affiliated-tools-under-shell" class="headerlink" title="Affiliated tools under shell"></a>Affiliated tools under shell</h2><h3 id="Get-all-filenames-as-var-by"><a href="#Get-all-filenames-as-var-by" class="headerlink" title="Get all filenames as var by `"></a>Get all filenames as var by `</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> file <span class="keyword">in</span> `ls | grep .jpg`</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">  newfile=`<span class="built_in">echo</span> <span class="variable">$file</span> | sed <span class="string">'s/dtest/cora/g'</span>`</span><br><span class="line">  mv <span class="variable">$file</span> <span class="variable">$newfile</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure><h3 id="String-slice"><a href="#String-slice" class="headerlink" title="String slice"></a>String slice</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="comment">#var&#125; # length of string var</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$&#123;alpha:3&#125;</span> <span class="comment"># display rest after first 3 chars</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$&#123;alpha:3:4&#125;</span> <span class="comment"># display 4 chars after first 3 chars</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$&#123;alpha: -3&#125;</span> <span class="comment"># display the last 3</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;sed&lt;/strong&gt; is a streaming text command-line tool in Linux and Mac OS(a little bit different). It can work perfect with RE to fi
      
    
    </summary>
    
    
      <category term="Computer-science" scheme="http://jaredlujr.github.io/categories/computer-science/"/>
    
    
      <category term="Linux" scheme="http://jaredlujr.github.io/tags/linux/"/>
    
      <category term="Command-line" scheme="http://jaredlujr.github.io/tags/command-line/"/>
    
      <category term="sed" scheme="http://jaredlujr.github.io/tags/sed/"/>
    
  </entry>
  
  <entry>
    <title>Counting the number of permutations</title>
    <link href="http://jaredlujr.github.io/2020/03/26/2020-03-26-stirling1/"/>
    <id>http://jaredlujr.github.io/2020/03/26/2020-03-26-stirling1/</id>
    <published>2020-03-25T16:00:00.000Z</published>
    <updated>2020-03-27T13:28:28.184Z</updated>
    
    <content type="html"><![CDATA[<p>Permutation group is an important instance in group theory. And each permutation $\pi$ can be uniquely decomposed into the combination of <strong>cycles</strong>. Then the number of such permutation in the known permutation group with specific cycles decompostion is correlated with <strong>Stirling numbers of the first kind</strong>.</p><h2 id="Term-definition"><a href="#Term-definition" class="headerlink" title="Term definition:"></a>Term definition:</h2><ul><li>finite set with order $n$: $X$, which is also isomorphic with $[n]$</li><li>the permutation group over $X$: $S_n$, obviously $\left| S_n \right| = n!$</li><li>some permutation in $S_n$:  $\pi=\pi(1)\pi(2)\dots \pi(n)$<ul><li>In fact, it is same as full-permutation</li></ul></li><li>the cyclic decompostion of permutation $\pi$: given $\pi \in S_n, i\in [n]$, there must exist a cycle $(i,\pi(i),\pi^2(i),\dots,\pi^{s-1}(i), i)$ (denoted as $C$), where $s$ is the least positive integer constructing such cycle. Then it is obvious that $\forall x \in [n]$ has to belong to one and only one cycle, and thus we have the cyclic decompostion of given permutation:</li></ul><script type="math/tex; mode=display">\pi = C_1\dots C_k</script><p>which is unique for given $\pi$, thus forming an one-to-one.</p><ul><li><p>the pattern(type) of permutation: in terms of the decompostion above, if there are totally $\lambda_s$ cycles with length of $s$, then we can write the pattern of such cyclic decompostion: $1^{\lambda_1}2^{\lambda_2}\dots n^{\lambda_n}$. Such as: (147)(25)(3)(6) is $1^2 2^1 3^1$ type.</p></li><li><p>conjugative relation ( which is also an <strong>equivalence relation</strong>): $\pi - \pi’ ~ if ~ \exists ~\rho \in S_n ~s.t. ~\pi’ = \rho\pi\rho^{-1}$</p></li><li><strong>[Prop]</strong>  $\pi, \pi’ \in S_n $ are conjugative if and only if they share the same pattern.</li></ul><h2 id="Stirling-numbers-of-the-first-kind"><a href="#Stirling-numbers-of-the-first-kind" class="headerlink" title="Stirling numbers of the first kind"></a>Stirling numbers of the first kind</h2><p>Here, we first give the definition of such Stirling numbers $s(n,k)$, then talking about its property and relations to the second kind.</p><h3 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h3><p>Given $n,k \in S_n$, the number of permutations those can be exactly decomposed into $k$ cycles is denoted as $c(n,k)$, then let</p><script type="math/tex; mode=display">s(n,k) = (-1)^{n+k} c(n,k)</script><p>which is called <em>Stirling numbers of the first kind</em>.</p><p>We appoint that</p><ul><li>$s(n,0) = c(n,0) = 0 ~(n&gt;0) $</li><li>$s(0,0)= c(0,0) = 1$</li><li>$s(n,k) = c(n,k) = 0,~ n &lt; k$</li></ul><h3 id="Recursive-relation"><a href="#Recursive-relation" class="headerlink" title="Recursive relation"></a>Recursive relation</h3><ul><li>$c(n,k) = c(n-1,k-1) + (n-1)c(n-1,k)$</li><li>$s(n,k) = s(n-1,k-1) - (n-1)s(n-1,k)$</li></ul><h3 id="Expansion"><a href="#Expansion" class="headerlink" title="Expansion"></a>Expansion</h3><p>Let $x$ be indefinite element, then</p><ul><li><script type="math/tex; mode=display">(x)_n = \sum_{k=0}^n s(n,k) x^k</script></li><li><script type="math/tex; mode=display">(x)^n = \sum_{k=0}^n c(n,k) x^k</script></li></ul><p>which are respectively $n-$ downward and upward factorial.</p><h3 id="Dual-expansion-with-“the-second-kind”"><a href="#Dual-expansion-with-“the-second-kind”" class="headerlink" title="Dual expansion with “the second kind”"></a>Dual expansion with “the second kind”</h3><p>Since have known the following expansion:</p><ul><li><script type="math/tex; mode=display">(x)_n = \sum_{k=0}^n s(n,k) x^k</script></li><li><script type="math/tex; mode=display">x^n = \sum_{k=0}^n S(n,k) (x)_k</script></li></ul><p>We can spot their dual relations at once.</p><p>Moveover, we can deduce more magic result from them two.</p><p>Because the $s(k,m) = 0$ if $m &gt; k$, we have:</p><script type="math/tex; mode=display">x^n = \sum_{k=0}^n S(n,k) (x)_k = \sum_{k=0}^n S(n,k) \sum_{m=0}^k s(k,m) (x)_m \\= \sum_{m=0}^k \left(\sum_{k=0}^n S(n,k)s(k,m) \right) x^m</script><p>_(Check it! It holds since we let some terms be zero )_</p><p>We immediately have:</p><script type="math/tex; mode=display">\sum_{k=0}^n S(n,k)s(k,m)  = \delta_{mn}</script><p>In the form of matrix, we can know that $n+1$-order matrices $S_n^{(2)} = (S(i,j))~(i,j=0,1,\dots)$ and $S_n^{(1)} = (s(i,j))$ are mutually inversive.</p><script type="math/tex; mode=display">S_n^{(1)} S_n^{(2)} = S_n^{(2)} S_n^{(1)} = \mathit I</script><hr><p><strong>Reference</strong></p><p>Wikipedia: <a href="https://en.wikipedia.org/wiki/Stirling_numbers_of_the_first_kind" target="_blank" rel="noopener">Stirling numbers of the first kind</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Permutation group is an important instance in group theory. And each permutation $\pi$ can be uniquely decomposed into the combination of
      
    
    </summary>
    
    
      <category term="Math" scheme="http://jaredlujr.github.io/categories/math/"/>
    
    
      <category term="Combinatorics" scheme="http://jaredlujr.github.io/tags/combinatorics/"/>
    
  </entry>
  
  <entry>
    <title>Note of SVM-(3)</title>
    <link href="http://jaredlujr.github.io/2020/03/26/2020-03-26-svm3/"/>
    <id>http://jaredlujr.github.io/2020/03/26/2020-03-26-svm3/</id>
    <published>2020-03-25T16:00:00.000Z</published>
    <updated>2020-03-31T13:42:26.022Z</updated>
    
    <content type="html"><![CDATA[<p>After magically transforming the optimization problem into a very simple inner products, we continues to introduce the powerful tool, <strong>kernels</strong>. The previous contents: <a href="https://jiaruilu.com/2020/03/24/svm1.html" target="_blank" rel="noopener">SVM-(1)</a>,<a href="https://jiaruilu.com/2020/03/24/svm2.html" target="_blank" rel="noopener">SVM-(2)</a></p><h2 id="Kernels"><a href="#Kernels" class="headerlink" title="Kernels"></a>Kernels</h2><h3 id="Terms"><a href="#Terms" class="headerlink" title="Terms:"></a>Terms:</h3><p>Suppose the original input is $x$, for instance, $x$ can be the living area of a house. Then:</p><ul><li>input attributes of a problem: $x$</li><li>input features: $[x,x^2,x^3]^T$ ( any derivative ones )</li><li>feature mapping $\phi$: <em>attr.</em> $\to$ <em>feat.</em> (in short it is, such mapping can be dimension-reducting or increasing)</li></ul><h3 id="Definition-of-Kernel"><a href="#Definition-of-Kernel" class="headerlink" title="Definition of Kernel"></a>Definition of Kernel</h3><p>Remember that we have obtained the final prediction expression in a form of inner products. Then the <em>feature mapping</em> will replace all the $\langle x,z \rangle$ with $\langle \phi(x),\phi(z) \rangle$. Specifically, given a feature mapping $\phi$, we define the corresponding <strong>kernel</strong> to be</p><script type="math/tex; mode=display">K(x,z) = \langle \phi(x),\phi(z) \rangle =  \phi(x)^T \phi(z)</script><p>Remarks:</p><ul><li>the computation of $K(x,z)$ is often inexpensive while that of $\phi(x)$ is the other extreme, because it is such a high-dimensional vector.</li><li>For example, consider $K(x,z) = (x^Tz)^2$, where finding $K(x,z)$ takes only $O(n)$ time — linear in the dimension of the input <strong>attributes</strong> whereas it is $O(n^2)$ complexity for $\phi(x)$</li><li>$K(x,z)$, just as inner product defined in Euclidean space, is a measure of how similar, say close the $x,z$ are.</li></ul><p>An important kernel with <strong>infinite dimensional feature mapping</strong> is the Gaussian kernel in the following form:</p><script type="math/tex; mode=display">K(x,z) = exp(-\frac{||x-z||^2}{2\sigma^2})</script><p>This is a reasonable measure of $x$ and $z$’s similarity. However, when we try to do some generalization works, we have to check its validity by $K(x,z) = \phi(x)^T \phi(z)$, if there exists some $\phi(\cdot)$ satisfying for all $x,z$?</p><p>(Note: we only ask the $\phi$ enabling $K(x,z) = \phi(x)^T \phi(z)$ to hold in terms of $x,z$ in our dataset )</p><p>We directly give the following theorem:</p><p><strong>Theorem (Mercer)</strong> $K: R^n \times R^n \to R $ is a valid ( Mercer ) kernel if and only if for any ${x^{(i)}} (m &lt; \infty)$, the corresponding kernel matrix $( K(x^{(i)},x^{(j)}) )_{m\times m}$ is symmetric positive semi-definite.</p><p>Here is a simple case study: consider input attributes $x$ is a sequence of amino acids, say a string of letters. Let $\phi$ be a feature vector that counts the number of occurrences of each length-k substring in $x$. As for the English letters, there are $26^k$ possible substrings and now $\phi(x)$ is a $26^k$ dimensional vector which is definitely too large to work with. However, by applying DP string matching algorithms, it is efficient to compute $K(x,z)$ directly. We just <strong>implicit</strong> work in such $26^k$-dimensional feature space.</p><p>Note that the idea of “kernel tricks” is way broader than the application in SVMs. Any learning function written in the form of inner products can be replaced by $K(x,z)$ thus magically enabling the algorithm to work in the higher-dimensional feature space.</p><p>However, as long as the high-dimensional features can be learned, the overfitting problem is followed. As shown above, some kernels offer great insights in the higher space, which equivalently “increase the number of the parameters”. The Gaussian Kernel, say <strong>radial basis function</strong>, is able to mapping the attributes into infinite dimensional space. It incredibly increase the probability to overfit the dataset. On the other hand, without powerful kernels, it is impossible for SVM, a linear model, to outperform LR so much, which exhibits great redundancy to introduce many constructs and conditions without better performance though. It is a trade-off to make decision.</p><hr><p><strong>Reference</strong>: <a href="http://cs229.stanford.edu/notes/cs229-notes3.pdf" target="_blank" rel="noopener">Stanford CS229-note3</a> by Andrew Ng</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;After magically transforming the optimization problem into a very simple inner products, we continues to introduce the powerful tool, &lt;st
      
    
    </summary>
    
    
      <category term="Computer-science" scheme="http://jaredlujr.github.io/categories/computer-science/"/>
    
    
      <category term="Machine-learning" scheme="http://jaredlujr.github.io/tags/machine-learning/"/>
    
      <category term="Support-vector-machine" scheme="http://jaredlujr.github.io/tags/support-vector-machine/"/>
    
      <category term="SVM" scheme="http://jaredlujr.github.io/tags/svm/"/>
    
  </entry>
  
  <entry>
    <title>Note of SVM-(2)</title>
    <link href="http://jaredlujr.github.io/2020/03/24/2020-03-24-svm2/"/>
    <id>http://jaredlujr.github.io/2020/03/24/2020-03-24-svm2/</id>
    <published>2020-03-24T12:00:00.000Z</published>
    <updated>2020-03-31T13:44:49.426Z</updated>
    
    <content type="html"><![CDATA[<p>Followed by <a href="https://jiaruilu.com/2020/03/24/svm1.html" target="_blank" rel="noopener">SVM-(1)</a>, our discussion of SVM continues in this post. Here, we will interpret the <em>Lagrange duality</em>, <em>KKT conditions</em>, which are very important to the reinforcement of SVM: the introduction of kernel functions.</p><h2 id="Note-of-SVM-2-Lagrange-duality-KKT-conditions-and-kernels"><a href="#Note-of-SVM-2-Lagrange-duality-KKT-conditions-and-kernels" class="headerlink" title="Note of SVM-(2): Lagrange duality, KKT conditions and kernels"></a>Note of SVM-(2): Lagrange duality, KKT conditions and kernels</h2><p><em>Review:</em> According to the last post, we state that building up hyperplane is to solve the optimization problem:</p><script type="math/tex; mode=display">\min_{w,b} {1\over 2} ||w||^2</script><script type="math/tex; mode=display">s.t. ~ y^{(i)}(w^T x^{(i)} + b) \geq 1</script><p>Before we move on, we branch out to talk about the <strong>Lagrange duality</strong> of such optimization. Consider the following optimization problem with both equality and inequality constraints ( <em>called primal problem ,relatively</em> ) :</p><p>$\min_{w} f(w)$<br>$s.t. g_i(w) \leq 0, i=1,\dots,k$<br>$s.t. h_i(w) = 0   ,i = 1,\dots,l$</p><p>And then we define the (generalized) <strong>Lagrangian</strong> of it:</p><script type="math/tex; mode=display">L(w,\alpha,\beta) = f(w) + \sum_{i=1}^k a_i g_i{w} + \sum_{i=1}^l \beta_i h_i(w)</script><p>where $\alpha$’s and $\beta$’s are the Lagrange multipliers. Then we define the following quantity:</p><script type="math/tex; mode=display">\theta_p(w) = \max_{\alpha,\beta,\alpha \geq 0} L(w,\alpha,\beta)</script><p>Actually, the $\theta_p(w)$ is equal to $f(w)$ if $w$ satisfies all the primal constraints; otherwise, it goes up to $\infty$.</p><p>Please keep that in mind, we immediately derive:</p><script type="math/tex; mode=display">\min_w \theta_p(w) = \min_w \max_{\alpha,\beta,\alpha \geq 0} L(w,\alpha,\beta)</script><p>which is also equivalent to $\min_w f(w)$ under all of the constraints.</p><p>We denote $\min_w \theta_p(w)$ as $p^\ast$, called the <strong>value</strong> of the primal problem.</p><p>Correspondingly, we define the <strong>dual</strong> as:</p><script type="math/tex; mode=display">\theta_D(w) = \min_{\alpha,\beta,\alpha \geq 0} L(w,\alpha,\beta)</script><p>also with the dual optimization problem:</p><script type="math/tex; mode=display">\max_w \theta_D(w) = \max_w \min_{\alpha,\beta,\alpha \geq 0} L(w,\alpha,\beta)</script><p><em>(where $\max_w \theta_D(w)$ is denoted by $d^\ast$ similarly)</em></p><p>Without proof, we claim that the “max min” of a function is always less than or equal to the “min max”, i.e.,</p><script type="math/tex; mode=display">d^\ast = \max_w \min_{\alpha,\beta,\alpha \geq 0} L(w,\alpha,\beta) \leq \min_w \max_{\alpha,\beta,\alpha \geq 0} L(w,\alpha,\beta) = p^\ast</script><p>But what we really care is the condition rendering:</p><script type="math/tex; mode=display">d^\ast = p^\ast</script><p>In fact, there must exist $w^\ast, \alpha^\ast, \beta^\ast$ such that $w^\ast$ is the solution to the <em>primal problem</em>; $\alpha^\ast, \beta^\ast$ are the solution to the <em>dual problem</em>, and moreover $d^\ast = p^\ast = L(w^\ast, \alpha^\ast, \beta^\ast)$. Furthermore, $w^\ast, \alpha^\ast, \beta^\ast$ satisfy the following conditions.</p><h3 id="Karush-Kuhn-Tucker-KKT-conditions"><a href="#Karush-Kuhn-Tucker-KKT-conditions" class="headerlink" title="Karush-Kuhn-Tucker (KKT) conditions"></a>Karush-Kuhn-Tucker (KKT) conditions</h3><script type="math/tex; mode=display">{\partial \over \partial w_i} L(w^\ast, \alpha^\ast, \beta^\ast) = 0</script><script type="math/tex; mode=display">{\partial \over \partial \beta_i} L(w^\ast, \alpha^\ast, \beta^\ast)</script><script type="math/tex; mode=display">\alpha^\ast_i g_i(w^\ast) = 0</script><script type="math/tex; mode=display">g_i(w^\ast) \leq 0</script><script type="math/tex; mode=display">\alpha \geq 0</script><p>What’s more important, is that if some $w^\ast, \alpha^\ast, \beta^\ast$ satisfy the KKT conditions, then it is also a solution to the primal and dual problems.</p><p><strong>Remarks:</strong></p><p>Note that the third equation $\alpha^\ast_i g_i(w^\ast) = 0$, which is called the KKT dual complementarity condition, implies that if $\alpha^\ast_i &gt; 0$, then $g_i(w^\ast) = 0$.</p><h3 id="Optimal-margin-classifiers"><a href="#Optimal-margin-classifiers" class="headerlink" title="Optimal margin classifiers"></a>Optimal margin classifiers</h3><p>Get back to our original problem:</p><script type="math/tex; mode=display">\min_{w,b} \frac{1}{2} ||w||^2</script><script type="math/tex; mode=display">s.t. y^{(i)}(w^T x^{(i)} + b) \geq 1</script><p>We can write the constraints as</p><script type="math/tex; mode=display">g_i(w) = -y^{(i)}(w^T x^{(i)} + b) + 1 \leq 0</script><p>Note that we have one such constraints for each training example and according to _KKT dual complementarity condition_, we will have $\alpha &gt; 0$ only for the training example those having functional margin exactly equal to one ( $g_w(w) = 0 $ ).</p><p><img src="/images/svm2-1.png" alt="alt img1"></p><p>The points with the smallest margins are the ones closest to the decision boundary( on dash lines as shown in the figure).<br>These are called the <strong>support vectors</strong>, the number of which is far less than the whole dataset.</p><p>When we construct the lagrangian for our optimization problem we have:</p><script type="math/tex; mode=display">L(w,b,\alpha) = {1\over 2} ||w||^2 - \sum_{i=1}^m \alpha_i [y^{(i)}(w^T x^{(i)} + b) - 1]</script><p>where the $\beta$ disappear because we only have inequality constraints. By setting the derivatives( may say gradient ) of $L$ w.r.t $w,b$ to zero, the expression of $w,b$ is obtained. Plugging them back to the dual problem, we have:</p><script type="math/tex; mode=display">L(w,b,\alpha) = \sum_{i=1}^m \alpha_i+ {1\over 2}  \sum_{i,j=1}^m y^{(i)} y^{(j)}\alpha_i \alpha_j (x^{(i)})^T x^{(i)}</script><p>Then we have the optimization problem as ( inner product form ):</p><p>$\max_\alpha W(\alpha) = \sum_{i=1}^m \alpha_i + {1\over 2} \sum_{i,j=1}^m y^{(i)} y^{(j)}\alpha_i \alpha_j \langle x^{(i)} x^{(i)} \rangle$</p><p>$s.t. ~~ \alpha_i \geq 0$</p><p>$\sum_{i=1}^m \alpha_i y^{(i)} = 0$</p><p>However, we should also be able to verify that the KKT conditions and $d^\ast = p^\ast$ are satisfied so that we can solve this dual in lieu of primal problem.</p><p>If some methods can be applied to solve the optimal $\alpha_i, ~i =1,\dots,m$, then we are able to subsequently compute the:</p><ul><li>$w(\alpha, y,x)$</li><li>$b(w,y,x)$</li></ul><p>The final form for our predicition task is obtained when we applied the optimal $w,b$ to compute the $\hat y$ with the new data $x$:</p><script type="math/tex; mode=display">w^T + b = (\sum_{i=1}^m \alpha^i y^{(i)}x^{(i)} )^T x + b\\= \sum_{i=1}^m \alpha^i y^{(i)} \langle x^{(i)},  x \rangle + b</script><p>Just like the <strong>KNN</strong>, we use the training samples to “directly” finish the prediction in the form of inner products. But however, we do not need to exhaust the whole dataset, which is time-consuming. Instead, according to the KKT conditions, non-zero $\alpha_i$ arises only for a small number of support vectors! Such that:</p><script type="math/tex; mode=display">w^T + b = \sum_{support ~ vector ~\{i\}} \alpha^i y^{(i)} \langle x^{(i)},  x \rangle + b</script><p>Note that by examining the dual form of the optimization problem, we gained significant insight into the structure of the problem, thus writing the algorithm as inner products, which plays an important role in kernel trick.</p><p><strong>In summary</strong>, we introduce the dual form of the primal problem and transform the optimization “$\min \max$” into “$\max \min$”. By taking derivatives and let them be zero, we replaced the $w(\alpha,x,y),b(\alpha,x,y)$ by $\alpha$; after solving the optimal $\alpha$, we plug tem in obtaining the parameters of SVM classifier. In the final step, we only use those samples which belong to $\alpha_i &gt; 0$ and greatly reduce the computation cost.</p><hr><p><strong>Reference</strong>: <a href="http://cs229.stanford.edu/notes/cs229-notes3.pdf" target="_blank" rel="noopener">Stanford CS229-note3</a> by Andrew Ng</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Followed by &lt;a href=&quot;https://jiaruilu.com/2020/03/24/svm1.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;SVM-(1)&lt;/a&gt;, our discussion of SVM continu
      
    
    </summary>
    
    
      <category term="Computer-science" scheme="http://jaredlujr.github.io/categories/computer-science/"/>
    
    
      <category term="Machine-learning" scheme="http://jaredlujr.github.io/tags/machine-learning/"/>
    
      <category term="Support-vector-machine" scheme="http://jaredlujr.github.io/tags/support-vector-machine/"/>
    
      <category term="SVM" scheme="http://jaredlujr.github.io/tags/svm/"/>
    
  </entry>
  
  <entry>
    <title>Note of SVM-(1)</title>
    <link href="http://jaredlujr.github.io/2020/03/24/2020-03-24-svm1/"/>
    <id>http://jaredlujr.github.io/2020/03/24/2020-03-24-svm1/</id>
    <published>2020-03-24T00:00:00.000Z</published>
    <updated>2020-03-31T09:03:06.872Z</updated>
    
    <content type="html"><![CDATA[<p>In the following posts, we will move on to the discussion about one important basic method in machine learning: Support Vector Machines(SVM). To be honest, SVM is a family of classifier which is based on the optimization tasks. First things first, some important concepts will be introduced as prerequisites.</p><h2 id="Note-of-SVM-1-Margins-confidence-and-classification"><a href="#Note-of-SVM-1-Margins-confidence-and-classification" class="headerlink" title="Note of SVM-(1): Margins, confidence and classification"></a>Note of SVM-(1): Margins, confidence and classification</h2><p>It is definitely not a very strange topic when it comes to classification. There is already simple but powerful tool, Logistic regression, serving for an effective model of classification. It provides straightforward rules for discrimination. However, SVM is a little bit different from LR.</p><p>Consider the following two clusters of points as data samples on a plane.</p><p><img src="/images/svm1-1.png" alt="alt img1"></p><p>Our task is to find a proper line, or more generally, <strong>separating hyperplane</strong>, as our discriminative rule for classification. Instead of parameter estimation of $\theta$ by MLE with regard to the probability of dataset, we rather maximize the <strong>“confidence”</strong> of our predictions.</p><p>The confidence is high if the prediction point is located way more distant from the separating hyperplane. In LR case, it happens when the $abs(\theta^T x)$ is large. Thus, we will be sure enough that our prediction is good. This seems to be a nice goal to aim for, and after formalize this idea, we obtain the basic idea of SVM.</p><h3 id="Functional-Margins"><a href="#Functional-Margins" class="headerlink" title="Functional Margins"></a>Functional Margins</h3><p>As the $\theta^T x = 0$ gives a decision boundary between the positive training examples and negative ones, we define such a measure of “how good” the dataset being separated, called functional margins.</p><script type="math/tex; mode=display">\hat{\gamma}^{(i)} = y^{(i)}(w^T x^{(i)} + b)</script><p>where $y^{(i)} \in {-1,1}$ holds the sign to be non-negative for convenience, $\{(x^{(i)},y^{(i)})\}$ as the dataset, and thus our hypothesis is</p><script type="math/tex; mode=display">h_{w,b} = g(w^T x + b); ~g(z)=1( z\geq 0), ~g(z)= -1 (otherwise)</script><p>According to the “best separating” idea, we definitely would like to maximize such measure, but not for all! We can know better by thinking it over: in fact only the “closest” point is useful for determining our hyperplane. So among the whole dataset, we need firstly find such “closest” point, also called <strong>support vector</strong>:</p><script type="math/tex; mode=display">\hat{\gamma}= \min_i \hat{\gamma}^{(i)}</script><p><img src="/images/svm1-2.png" alt="alt img2"></p><p>Before we go further, we can add a little trick to the $\gamma$ stuff by geometric insights. Actually, we can do some normalization operation without changing the meaning of our goal:</p><script type="math/tex; mode=display">{\gamma}^{(i)} = y^{(i)}((\frac{w}{||w||})^T x^{(i)} + \frac{b}{||w||})</script><p>So far, we have applied a proposition that arbitrary scaling for $w \to w/4 ~and~ b\to b/4$ does no effect on the support vector selection in the context of “margin”.</p><h3 id="Optimal-classifier"><a href="#Optimal-classifier" class="headerlink" title="Optimal classifier"></a>Optimal classifier</h3><p>Since the minimal $\gamma$ provides the critical points in the plane for determining our decision boundary, say separating hyperplane, we now state our goal formally in terms of optimization.</p><p>$ \max_{\gamma,w,b} \gamma$</p><p>$<del>~</del> s.t. <del>y^{(i)}(w^T x^{(i)} + b) \geq \gamma$<br>$</del>~~~||w|| = 1$</p><p>However, this lies a non-convex constraint “$||w|| =1 $””, we now change it into:</p><p>$ \max_{\hat\gamma,w,b} {\hat\gamma \over ||w||}$</p><p>$<del>~</del> s.t. ~~y^{(i)}(w^T x^{(i)} + b) \geq \hat\gamma$</p><p>But still, the non-convex scenario appears again on the objective function. We then set $\hat\gamma =1$ and transform the task into minimizing $w$:</p><p>$\min_{w,b} {1\over 2} ||w||^2$</p><p>$<del>~</del> s.t. ~~y^{(i)}(w^T x^{(i)} + b) \geq 1$</p><p>The solution of above directly gives us the <strong>optimal margin classifier</strong>. And such optimization problem can be solved easily using quadratic programming (QP) algorithm.</p><p><em>Remarks</em>:</p><ul><li>We assume that the dataset $\{(x^{(i)},y^{(i)})\}$ is linear separable</li><li>It is still a simple classifier which may not outperform the LR model. In the next post, some improvement will be introduced to reinforce it.</li></ul><hr><p><strong>Reference</strong>: <a href="http://cs229.stanford.edu/notes/cs229-notes3.pdf" target="_blank" rel="noopener">Stanford CS229-note3</a> by Andrew Ng</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;In the following posts, we will move on to the discussion about one important basic method in machine learning: Support Vector Machines(S
      
    
    </summary>
    
    
      <category term="Computer-science" scheme="http://jaredlujr.github.io/categories/computer-science/"/>
    
    
      <category term="Machine-learning" scheme="http://jaredlujr.github.io/tags/machine-learning/"/>
    
      <category term="Support-vector-machine" scheme="http://jaredlujr.github.io/tags/support-vector-machine/"/>
    
      <category term="SVM" scheme="http://jaredlujr.github.io/tags/svm/"/>
    
  </entry>
  
  <entry>
    <title>Hidden Markov model and Viterbi algorithm</title>
    <link href="http://jaredlujr.github.io/2020/03/23/2020-03-23-viterbi/"/>
    <id>http://jaredlujr.github.io/2020/03/23/2020-03-23-viterbi/</id>
    <published>2020-03-22T16:00:00.000Z</published>
    <updated>2020-03-27T13:27:49.968Z</updated>
    
    <content type="html"><![CDATA[<p>The <strong>Viterbi algorithm</strong> is a <strong>dynamic programming(DP)</strong> algorithm for finding the most likely sequence of hidden states, called the Viterbi path, which results in a sequence of observed events, especially in the context of Markov information sources and <strong>hidden Markov models(HMM)</strong>.</p><blockquote><p>Markov property indicates the independency of history information.</p></blockquote><p>Viterbi algorithm exhibits the very same idea shared with Markov by integrating all the past information to the current state(memorization), thus <strong>decomposing the problem</strong> into sub-problems.</p><p>Let us consider a simple case: to find the shortest weighted path (say transition probabilities in the context of HMM) between two node in the graph.</p><p><img src="/images/viterbi-1.gif" alt="alt img1"></p><p>The central idea of Viterbi is straightforward: in order to reduce the price of searching process, we cut off useless paths(for shortest optimization) immediately when we know their “uselessness”. In the meantime, the best path to a specific node in the current layer $t$ (say time) is definite, which means that we can throw paths otherwise away. The memorization is done such that the total computing price is reduces.</p><p>(Remarks: It is like beam search to trim(or called prune) in the space domain, while Viterbi is the trimming in the time domain(since we consider from the perspective of State Transition graph).</p><h2 id="Viterbi-algorithm-Pseudocode"><a href="#Viterbi-algorithm-Pseudocode" class="headerlink" title="Viterbi algorithm: Pseudocode"></a>Viterbi algorithm: Pseudocode</h2><p>We firstly define the notion as follows and then narrate the strict definition of such algorithm:</p><ul><li>Observation space $O = {o_1,o_2,\dots,o_N}$</li><li>The state space $S={s_1,s_2,\dot,s_K}$</li><li>Algorithm optimized path $X=(x_1,x_2,\dots,x_T)$ as a sequence of states $x_n \in S$</li><li>Observation trajectory $Y=(y_1,y_2,\dots,y_T)$ with $y_n \in O$$ which is generated by $X$</li><li>Array of initial probabilities $\Pi=(\pi_1,\pi_2,\dots,_pi_K)$ such that $\pi_i$ stores the probability that $x_1==s_i$</li><li>Sequence of observations $Y=(y_1,y_2,\dots,y_T)$ such that $y_t == i$ if the observations at time $t$ is $o_i$</li><li>transition matrix $A$ of size $K\times K$ such that A_{ij} stores the transition probability of transition from state $s_i$ to state $s_j$</li><li>emission matrix $B$ of size $K\times N$ such that $B_{ij}$ stores the probability of observing $o_j$ from state $s_j$</li></ul><p>Two 2-dimensional matrixs of size $K\times T$ are thus constructed:</p><ul><li><p>each element $T_1[i,j]$ of $T_1$ stores the probability of the most likely path so far $\hat{X} = (\hat{x_1},\hat{x_2},\dots,\hat{x_T})$ with $\hat{x_j} = s_j$ that generates $Y=(y_1,y_2,\dots,y_T)$</p></li><li><p>each element $T_2[i,j]$ of $T_2$ stores $\hat{x_{j-1}}$ of the most likely path so far $\hat{X} = (\hat{x_1},\hat{x_2},\dots,\hat{x_{j-1}},\hat{x_{j}}=s_i) ~\forall j, 2 \leq j \leq T$</p></li></ul><p>The table entries $T_1[i,j]$,$T_2[i,j]$ are filled by increasing order of $K\cdot j+i$</p><script type="math/tex; mode=display">T_1[i,j] = \max_k (T_1[k,j-1] \cdot A_{ki} \cdot B_{i y_j} )</script><p>and</p><script type="math/tex; mode=display">T_2[i,j] = arg\max_k(T_1[k,j-1]\cdot A_{ki})</script><p>The Pseudocode of Viterbi:</p><p><img src="/images/viterbi-2.png" alt="alt img2"></p><h3 id="Explanation"><a href="#Explanation" class="headerlink" title="Explanation"></a>Explanation</h3><p>If given HMM with its essential elements: state space $S$, initial probabilities $\pi_i$ and transition probabilities $a_{i,j}$, and our observation trajectory $(y_1,y_2,\dots,y_T)$, we then compute the most likely sequence $(x_1,x_2,\dots,x_T)$ the produce the observations.</p><blockquote><p>We compute only the possible combinations between current two layers.</p></blockquote><h4 id="Why-bother-discussing-probability"><a href="#Why-bother-discussing-probability" class="headerlink" title="Why bother discussing probability?"></a>Why bother discussing probability?</h4><p>In fact, it is way more powerful than that of optimal path search algorithm, when it comes to stochastic process. Hidden Markov model describes that the system being modeled is assumed to be a Markov process with unobservable (i.e. hidden) states.</p><p>In summary, therefore, using DP to solve the prediction in HMM is Viterbi algorithm. Firstly we compute each probabilities(Markov) for transition between the sequence. Then we trace back to collect the nodes thus obtain the optimal path.</p><h2 id="What-does-“Hidden”-mean"><a href="#What-does-“Hidden”-mean" class="headerlink" title="What does “Hidden” mean?"></a>What does “Hidden” mean?</h2><p>Consider the elements of HMM, the initial probabilities and state transition probabilities are, however causative, beyond the reach of our observation.</p><p>There are two main assumption behind:</p><ul><li>homogeneous Markov property</li><li>independent observation: observance only depends on the current state of Markov chain</li></ul><p>Observation probability distribution provides “how to” generate observation at a time given state.</p><hr><p><strong>Reference</strong>:</p><ul><li><a href="https://en.wikipedia.org/wiki/Viterbi_algorithm" target="_blank" rel="noopener">Wikipedia: Viterbi algorithm</a></li><li>Statistical Learning methods, by Li Hang (2012)</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;The &lt;strong&gt;Viterbi algorithm&lt;/strong&gt; is a &lt;strong&gt;dynamic programming(DP)&lt;/strong&gt; algorithm for finding the most likely sequence of hi
      
    
    </summary>
    
    
      <category term="Computer-science" scheme="http://jaredlujr.github.io/categories/computer-science/"/>
    
    
      <category term="Machine-learning" scheme="http://jaredlujr.github.io/tags/machine-learning/"/>
    
      <category term="Dynamic-programming" scheme="http://jaredlujr.github.io/tags/dynamic-programming/"/>
    
  </entry>
  
  <entry>
    <title>Structure decomposition - two main methods</title>
    <link href="http://jaredlujr.github.io/2020/03/23/2020-03-23-nlu-note3/"/>
    <id>http://jaredlujr.github.io/2020/03/23/2020-03-23-nlu-note3/</id>
    <published>2020-03-22T16:00:00.000Z</published>
    <updated>2020-03-27T13:27:07.389Z</updated>
    
    <content type="html"><![CDATA[<p>From a view of structural learning, we may review the classification task in machine learning. It is clear that most of NLP tasks are not of typical classification since it is nearly impossible or extremely time-consuming to perform such learning process, due to the large amount of labels, say different patterns to be predicted. However, we can make our model proper to assume classfier-like behavior by formularizing both form of input and output representatiion.</p><h2 id="Structural-decomposition"><a href="#Structural-decomposition" class="headerlink" title="Structural decomposition"></a>Structural decomposition</h2><p>No structural learning can be straightforwardly and effectively solved until the convertion task is performed. It is called structure decomposition (encoding), which converts the graphs into low-class classification subtasks. Correspondingly, there also exists a re-building step before structure prediction, called <strong>decoding</strong> to give us the formularized prediction results.</p><p>There are two types of decomposition strategies: contemporary decomposition and diachronic decomposition, which will be discussed in the following sections. Another thing needed to mention is that the input can always have a form of linear sequence, for convenience.</p><h3 id="Contemporary-decomposition"><a href="#Contemporary-decomposition" class="headerlink" title="Contemporary decomposition"></a>Contemporary decomposition</h3><ul><li>a graph model (space-dimension decomposition)</li><li>polynomial time complexity $O(L^{f(n)})$for decoding in the SAME pattern</li><li>accurately done</li></ul><blockquote><p>Structure is decomposed into pieces, decoding is done by searching the space of all possible structure candidates.</p></blockquote><p>For a structure learning sample $\{X,G\}$, where $X$ is input structure, $G$ is structure for prediction which is represented as a graph decomposed into sub-graphs $G_1,G_2,\dots,G_n$</p><p>where</p><script type="math/tex; mode=display">G=\bigcup_{j=1}^n G_j</script><ul><li>W.L.O.G, decomposition of input structure $X$ is ignored.</li><li>The union is not necessarily disjoint( the overlapping may exist between sub-graphs)</li></ul><h4 id="The-training-of-graph-model"><a href="#The-training-of-graph-model" class="headerlink" title="The training of graph model"></a>The training of graph model</h4><p>We firstly define a score function _score($G_j$)_ to evaluate each <strong>sub-graph</strong>, such that</p><script type="math/tex; mode=display">G = arg\max_{\{G_j\}} \sum_{j} score(X,G_j)</script><p>which means that the optimal decomposition strategy (optimal partition of $G$: $\{G_j\}_\ast$) gives the best sumup scores for each sub-graph. _Search algorithm is involved._</p><ul><li>the training is to derive proper score function</li><li>decoding is the maximizing of the scores’ sum-up</li></ul><h4 id="The-most-simple-case-linear-to-linear-sequence"><a href="#The-most-simple-case-linear-to-linear-sequence" class="headerlink" title="The most simple case: linear to linear sequence"></a>The most simple case: linear to linear sequence</h4><ul><li>The number of edges from maximum decomposed sub-graph is called order of such graph model</li><li>For the linear decomposition, if every sub-graphs are in the same pattern, then <strong>Viterbi decoding</strong> can be applied for seeking a analytic solution.</li></ul><p><img src="/images/nlu3-1.png" alt="alt img1"></p><ul><li>For the linear decomposition, if not every sub-graphs are in the same pattern, then only beam search decoding can be applied for <strong>approximate solution.</strong></li></ul><p><img src="/images/nlu3-2.png" alt="alt img2"></p><p>Now suppose a linear sequence for prediction is always decomposed into linear piece with $n+1$ nodes (namely, $n$ edges), <strong>step-wise overlapping</strong> among all these neighbored decomposed pieces.</p><p>_(the filter move step is only $1$, overlapping range is $n$)_</p><p>Formally, a sequence $x_1x_2\dotsx_m$ is decomposed into</p><script type="math/tex; mode=display">x_1x_2\dots x_{n+1}, ~x_2x_3\dots x_{n+2}, ~\dots , ~x_{m-n}x_{m-n+1}\dots x_m</script><p>We say this is an $n$-order hidden Markov model (HMM), where the score function is defined as logarithmic probability of each pieces.</p><h4 id="General-model-over-sub-graphs"><a href="#General-model-over-sub-graphs" class="headerlink" title="General model over sub-graphs"></a>General model over sub-graphs</h4><p><img src="/images/nlu3-3.png" alt="alt img3"></p><p>Generally speaking, the classifier should be determined heavily. Given a structure learning sample $\{X,G\}$, $X$ is decomposed into $\{X_i\}$, $G$ into $\{G_i\}$. Then $score(X_i,G_i)$ should be learned by the resulting classifier. Sometimes, the mapping from $X_i$ to $G_i$ is non-trivial.</p><p><img src="/images/nlu3-4.png" alt="alt img4"></p><h3 id="Diachronic-decomposition"><a href="#Diachronic-decomposition" class="headerlink" title="Diachronic decomposition"></a>Diachronic decomposition</h3><ul><li>a transition model (time-dimension decomposition)</li><li>linear time performance of greedy procedure</li><li>not necessarily finding global optimal decision</li><li>beam search with polynomial time complexity to improve</li></ul><blockquote><p>Structure is built step by step, decoding is to make decision about the best building operation each time.</p></blockquote><p><img src="/images/nlu3-5.png" alt="alt img5"></p><p>Given a structure learning sample $\{X,G\}$, $G$’s formation is performed by a series of operation $\{b_1,b_2,\dots\}$.</p><p>We then instead use $score(X, G_C,b_i)$ to evaluate every building operation of $G$. The whole $G$ (say all the edges) is established step-wise during the <strong>decoding</strong>: we <strong>greedily</strong> follow the chosen graph building operation according to the classifier prediction with highest scoring.</p><p>Every time, after a building operation is performed, the graph building status (context) should be updated, $G_C = G_C^\ast$ ; Repeatedly, the last $G_C^\ast$ will be the graph predicted by the model,</p><script type="math/tex; mode=display">G_C^\ast = arg\max_{b_i} score(X, G_C, b_i)</script><blockquote><p>Sometimes, we may incorporate transition and graph models. There comes a model like step-wise re-ranking which achieve this, for example, the <strong>Easy-first dependency parsing</strong>. (Ref: _Yoav Goldberg, Michael Elhadad. 2010. An Efficient Algorithm for Easy-First Non-Directional Dependency Parsing. NAACL 2010._)</p></blockquote><h2 id="Two-variants-of-graph-model"><a href="#Two-variants-of-graph-model" class="headerlink" title="Two variants of graph model"></a>Two variants of graph model</h2><p>Given a structure learning sample $\{X, G\}$, based on decomposition of input structure $X$ and output structure $G$, there may comes two variants of graph model:</p><h3 id="Scoring-sub-graphs"><a href="#Scoring-sub-graphs" class="headerlink" title="Scoring sub-graphs"></a>Scoring sub-graphs</h3><p>Scoring is done on combination of aligned input and output sub-graphs (inside each dotted line frame).</p><ul><li>$x_i$ is node of <strong>input structure</strong> $X$, and $y_i$ is node of <strong>output structure</strong> $G$.</li></ul><p><img src="/images/nlu3-6.png" alt="alt img6"></p><ul><li>Easy and straightforward structure decomposition</li><li>Need a <strong>source-target alignment</strong> for candidate sub-graph generation, _sometimes hard_!</li><li>Easy-eg. POS tagging task from seq to seq</li><li>Haaaard-eg. statistical machine translation ( the mapping is not pair-wise following sequence )</li></ul><h3 id="Labeling-sub-graphs-tagging"><a href="#Labeling-sub-graphs-tagging" class="headerlink" title="Labeling sub-graphs(tagging)"></a>Labeling sub-graphs(tagging)</h3><p>This demonstrates <strong>learning a label</strong> for each output node $y_i$, and taking $x_i$ as mapping focus from input structure (automatically aligned), $x_{i-1}$ and $x_{i+1}$ as input context, $y_{i-1}$ as output context.</p><p><img src="/images/nlu3-7.png" alt="alt img7"></p><ul><li>Limit to the tag set size, cannot support too many classes for classifying</li><li>Usually no need of alignment</li></ul><hr><p><strong>Reference</strong>: Tutorial materials of Zhao Hai(Shanghai Jiao Tong Univ.);</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;From a view of structural learning, we may review the classification task in machine learning. It is clear that most of NLP tasks are not
      
    
    </summary>
    
    
    
      <category term="NLU" scheme="http://jaredlujr.github.io/tags/nlu/"/>
    
      <category term="Structural-learning" scheme="http://jaredlujr.github.io/tags/structural-learning/"/>
    
  </entry>
  
</feed>
